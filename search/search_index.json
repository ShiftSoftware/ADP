{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Auto Distributor Platform (ADP)","text":"<p>Dealers operating under a large auto distributor typically use stand-alone Dealership Management Systems (DMS) to manage their business operations.  </p> <p>The lack of integration between the DMS systems of the dealers and the distributor's systems causes significant inefficiencies and operational challenges.  </p> <p>There is a strong need for a centralized platform that provides seamless integration between the distributor, its dealers, and customers.</p> <p>The ADP is a set of seamlessly integrated software tools designed to streamline the operations of the distributor and its dealers.</p>"},{"location":"index.html#adp-hub-portal","title":"ADP Hub (Portal)","text":"<p>The ADP Hub is a web-based portal that provides a single point of access to the various tools and services offered by the ADP. In addition to links to the Core ADP Components, the Hub provides the following features:</p> <ol> <li>News &amp; Other Announcements from the Distributor</li> <li>Policies</li> <li>Repair Manuals</li> <li>File Sharing System between dealers and the distributor</li> </ol>"},{"location":"index.html#core-components-of-adp","title":"Core Components of ADP","text":"<p>The ADP consists of the following core components distributed as microservices:</p> <ul> <li>Identity System  \u2197</li> <li>Vehicle Database     \u2197</li> <li>Parts Database   \u2197</li> <li>Service Database     \u2197</li> <li>Support Ticket System    \u2197</li> <li>Customer Database    \u2197</li> </ul>"},{"location":"architecture/deployment-pipelines.html","title":"Deployment Pipelines","text":"<p>Each Microservice from the ADP is deployed using the following deployment pipelines:</p>"},{"location":"architecture/deployment-pipelines.html#staging-environment","title":"Staging Environment","text":"<p>Developers can deploy new versions of a microservice to the staging environment as shown in the diagram below.</p> <p></p> <p>You can see from the diagram that the staging deployment pipelines are triggered when a commit is tagged in the following format:</p> <ul> <li>release-all-*: Deploys all components of the Microservice to the staging environment.</li> <li>release-api-*: Deploys only the API component of the Microservice to the staging environment.</li> <li>release-web-*: Deploys only the Web component of the Microservice to the staging environment.</li> <li>release-functions-*: Deploys only the Functions component of the Microservice to the staging environment.</li> </ul>"},{"location":"architecture/deployment-pipelines.html#production-environment","title":"Production Environment","text":"<p>Production deployment pipelines are manually triggered by a developer. A developer can swap the staging environment with the production environment as shown in the diagram below.</p> <p></p>"},{"location":"architecture/stack.html","title":"Stack","text":"<p>The ADP consists of multiple systems that are distributed as Microservices developed using Microsoft's .NET 8.</p>"},{"location":"architecture/stack.html#microservices-architecture","title":"Microservices Architecture","text":"<p>Each Microservice is designed using the following architecture:</p> <p></p>"},{"location":"architecture/stack.html#sql-database","title":"SQL Database","text":"<p>Each Microservice has its own SQL Server Database. The SQL Database ensures exeptional data integrity as it's ACID compliant.</p> <p>Cloud Resources</p> <p>Two Azure SQL Databases are used (for Production &amp; Staging) by each Microservice.</p>"},{"location":"architecture/stack.html#web-api","title":"Web API","text":"<p>A RESTful Web API developed using .NET 8 that's responsible for handling all incoming requests from the web app dashboard. </p> <p>The Web APIs are not being consumed by external clients. For external clients, Serverless Function APIs are used.</p> <p>Cloud Resources</p> <p>An Azure App Service with two slots (for Production &amp; Staging) are used to host the Web APIs App of each Microservice.</p>"},{"location":"architecture/stack.html#serverless-functions","title":"Serverless Functions","text":"<p>Serverless Function APIs are used to expose APIs to external clients. Typically serving data that are stored in the NoSQL Database.  </p> <p>Serverless Functions are also used to handle background tasks and scheduled jobs.</p> <p>Cloud Resources</p> <p>An Azure Functions App with two slots (for Production &amp; Staging) are used to host the Serverless Functions of each Microservice.</p>"},{"location":"architecture/stack.html#key-vault","title":"Key Vault","text":"<p>Key Vault is used to store and manage application secrets such as connection string, API Keys, passwords, tokens, certificates, and any other sensetive information.  </p> <p>All the cloud resources are configured to access the Key Vault for secrets instead of storing them in configuration files or environment variables.</p> <p>Cloud Resources</p> <p>An Azure Key Vault is used for all the Microservices.</p>"},{"location":"architecture/stack.html#service-bus","title":"Service Bus","text":"<p>Service Buses are used to decouple the Microservices and enable asynchronous communication between them.</p> <p>Cloud Resources</p> <p>Two Azure Service Buses are used for all the Microservices.</p>"},{"location":"architecture/stack.html#blob-storage","title":"Blob Storage","text":"<p>Blob Storage is used to store large files such as images, videos, and documents.</p> <p>Cloud Resources</p> <p>One or more Azure Blob Storage accounts are used for all the Microservices.</p>"},{"location":"architecture/stack.html#frontend-web-app","title":"Frontend Web App","text":"<p>The Frontend Web App is a dashboard used for managing the data related to the Microservices.</p> <p>Cloud Resources</p> <p>An Azure Static Web App with two slots (for Production &amp; Staging) are used to host the Frontend Web App of each Microservice.</p>"},{"location":"architecture/stack.html#nosql-database","title":"NoSQL Database","text":"<p>Some data from the SQL Database is replicated to the NoSQL Database.   </p> <p>The NoSQL database acts as a shared layer between the Microservices that need to communicate with each other. It's also used by the Serverless Functions to serve data to external clients without the need to access the SQL Database.</p> <p>Cloud Resources</p> <p>Two or more Azure Cosmos DBs are used (for Production &amp; Staging) shared by all the Microservices.</p>"},{"location":"components/customers.html","title":"Customer Database","text":"<p>A consolidated database designed to store and manage customer information and interactions across all dealerships.</p>"},{"location":"components/identity.html","title":"Identity System","text":"<p>The Identity System is a centralized platform designed to manage and streamline the organizational structure of the distributor and its dealers.  </p> <p>It offers comprehensive features to manage companies, company branches (including their departments and services), users, permissions, and roles.</p> <p>Here is a video recording showing the Identity Dashboard:</p> <p>The following are the fundamental sections of the Identity System:</p>"},{"location":"components/identity.html#countries","title":"Countries","text":"<p>The countries where the distributor and its partners operate.</p>"},{"location":"components/identity.html#regions","title":"Regions","text":"<p>The regions where the distributor operates. These could represent countries, states, or provinces.</p>"},{"location":"components/identity.html#cities","title":"Cities","text":"<p>The cities where the distributor, its dealers, and customers are located.</p>"},{"location":"components/identity.html#brands","title":"Brands","text":"<p>The car brands that the distributor is authorized to sell. For example, below are the available brands of Toyota Motor Corporation:</p> <ul> <li>Toyota</li> <li>Lexus</li> <li>Hino</li> <li>Daihatsu</li> </ul>"},{"location":"components/identity.html#departments","title":"Departments","text":"<p>The facilities that a given dealer branch may have. Below are the available departments:</p> Name ID Showroom showroom Parts Shop parts-shop Service Center service-center Body Shop body-shop Quick Service Center quick-service-center"},{"location":"components/identity.html#services","title":"Services","text":"<p>The services that a given dealer branch may provide are described below:</p> Name ID New Vehicle Sale new-vehicle-sale Installment Sales installment-sales Used Car Sales used-car-sales Test Drive test-drive Parts Counter Sale parts-counter-sale Auto Repair &amp; Maintenance auto-repair-and-maintenance Body &amp; Paint body-and-paint <p>Note</p> <p>Services are associated with departments as follows:</p> Department Services Showroom New Vehicle Sale, Installment Sales, Used Car Sales, Test Drive Parts Shop Parts Counter Sale Service Center Auto Repair &amp; Maintenance Body Shop Body &amp; Paint Quick Service Center Auto Repair &amp; Maintenance"},{"location":"components/identity.html#companies","title":"Companies","text":"<p>The companies within the distributor network, including the distributor itself, TMC, dealers, suppliers, and other companies.</p>"},{"location":"components/identity.html#company-branches","title":"Company Branches","text":"<p>Every company must have at least one branch. A branch is a physical facility that may contain one or more departments providing one or more services.</p>"},{"location":"components/identity.html#access-trees","title":"Access Trees","text":"<p>An Access Tree is a grouping of actions (permissions). One or more Access Trees are assigned to a user.</p>"},{"location":"components/identity.html#users","title":"Users","text":"<p>A user belongs to a company branch and may have one or more Access Trees.</p>"},{"location":"components/identity.html#teams","title":"Teams","text":"<p>A team is a grouping of users. A team may contain one or more users.</p>"},{"location":"components/intro.html","title":"Core Components of ADP","text":"<p>The ADP consists of the following core components that are distributed as microservices:</p> <ul> <li>Identity System</li> <li>Vehicle Database</li> <li>Parts Database</li> <li>Service Database</li> <li>Support Ticket System</li> <li>Customer Database</li> </ul>"},{"location":"components/parts.html","title":"Parts Database","text":"<p>The parts database provides the following features:</p> <ul> <li>Genuine Manufacturer Part Information.</li> <li>Part availability at the Distributor Level.</li> <li>Deadstock part availability at the Dealer Level.</li> </ul>"},{"location":"components/parts.html#manufacturer-parts","title":"Manufacturer Parts","text":"<p>The manufacturer provides a large dataset containing all genuine part information. Dealers and the distributor can benefit from this for various purposes. The distributor compiles the parts from the manufacturer and may provide additional information such as pricing details (Cost Price, Retail Price, Warranty Price, etc.).</p>"},{"location":"components/parts.html#third-party-parts","title":"Third-Party Parts","text":"<p>The distributor may also provide third-party parts. These parts follow the same structure as the genuine parts but are not provided by the manufacturer. </p>"},{"location":"components/parts.html#distributor-part-availability","title":"Distributor Part Availability","text":"<p>Dealers can look up part numbers and check their availability from the distributor.</p>"},{"location":"components/parts.html#dealer-deadstock","title":"Dealer Deadstock","text":"<p>Dealers can share their deadstock, making these parts available to other dealers and the distributor during a part lookup. </p> <p>Note</p> <p>The Part Lookup feature combines data from all four sources and presents them to the user while searching for a part.</p>"},{"location":"components/parts.html#part-information","title":"Part Information","text":"<p>Parts are identified by a unique Part Number. Detailed information about a part is available in the integration document.</p>"},{"location":"components/tickets.html","title":"Support Ticket System","text":"<p>A centralized ticketing system that accepts inquiries and routes them to the appropriate dealer or distributor departments for resolution.</p>"},{"location":"components/tickets.html#ticket-types","title":"Ticket Types","text":"<p>There are five main types of tickets that can be created by users (Customers, Dealer, or Distributor Staff):</p> <ul> <li>General Inquiry: Requests for general information, complaints, or other feedback.</li> <li>Vehicle Quotation: Requests for a quotation for buying, selling, or trading a specific vehicle model.</li> <li>SSC Inquiry: Inquiries about the SSC information for an Unauthorized Vehicle.</li> <li>Service Booking: Requests for a service appointment for a vehicle.</li> <li>Test Drive: Requests for a test drive of a vehicle.</li> </ul>"},{"location":"components/tickets.html#ticket-assignment","title":"Ticket Assignment","text":"<p>Any given ticket can have the following assignment statuses:</p> <ul> <li>Unassigned: The ticket has not been assigned yet. It must be reviewed by the distributor and assigned to a dealer or distributor staff.</li> <li>Assigned to Dealer: The ticket has been assigned to a dealer (Company) without a specific branch/team. The dealer can assign the ticket to a specific branch or team.</li> <li>Assigned to Branch: The ticket has been assigned to a specific branch of a dealer or distributor.</li> <li>Assigned to Team: The ticket has been assigned to a specific team of a dealer or distributor.</li> </ul> <p>Note</p> <p>Dealers, Branches, and Teams are created and maintained on the Identity System.</p>"},{"location":"components/tickets.html#ticket-sources","title":"Ticket Sources","text":"<p>Tickets can be created from the following sources:</p> <ul> <li>Web Portal: The ticket is created by a user on the ticket web portal.</li> <li>API: The ticket is created using the API. The API can be called from any authorized external system (Website, Mobile App, Chatbot, etc.).</li> </ul>"},{"location":"components/tickets.html#ticket-status","title":"Ticket Status","text":"<p>Some of the most common statuses that a ticket can have are the following:</p> <ul> <li>New: The ticket has been created and has not been reviewed yet.</li> <li>In Progress: The ticket is being reviewed and worked on by the assigned dealer or distributor staff.</li> <li>On Hold: The ticket is on hold and is not being worked on.</li> <li>Pending Customer: The ticket is waiting for a response from the customer.</li> <li>Unresolved: The ticket cannot be resolved and is closed.</li> <li>Resolved: The ticket has been resolved and closed.</li> </ul>"},{"location":"components/tickets.html#communication-channels","title":"Communication Channels","text":"<p>The ticket system supports the following communication channels:</p> <ul> <li>Chat Apps: WhatsApp, Viber, Facebook Messenger, Telegram, etc.</li> <li>Email: Outgoing notifications only.</li> </ul> <p>Warning</p> <p>Chat App integration does not come out of the box and must be implemented in accordance with the third-party vendor that the distributor is using.</p>"},{"location":"components/vehicles.html","title":"Vehicle Database","text":"<p>A centralized repository that acts as a single source of truth for all matters related to vehicles, including but not limited to the following:</p>"},{"location":"components/vehicles.html#purpose","title":"Purpose","text":"<p>Automotive distributors are large enterprises with many branches and departments. Being a distributor, they also oversee the operations of many dealers across their network.</p> <p>Within this expansive structure, a distributor utilizes various platforms that are maintained internally, by dealers themselves, or by third-party developers.</p> <p>The following graph provides a top-level view of how a distributor may orchestrate the flow of data between its platforms and the external systems used by its dealers and the manufacturer. </p>"},{"location":"components/vehicles.html#data-governance","title":"Data Governance","text":"<p>The distributor's role within the network is essentially to apply Data Governance across all entities.  </p> <p>Data Governance involves managing the availability, usability, consistency, integrity, and security of the data employed in the enterprise.  </p> <p>By centralizing data, the distributor establishes a single source of truth (SSOT), ensuring that all companies, branches, departments, and platforms operate with the same accurate and up-to-date information.  </p> <p>This centralization aids in avoiding discrepancies and data silos that can arise when different parts of the organization use separate data sources.</p> <p>Simultaneously, by decentralizing responsibility, the distributor empowers each entity within its network to independently manage their specific operations.  This means that while data is centrally unified, the responsibility of utilizing this data for various tasks is distributed to the respective teams and platforms.</p>"},{"location":"components/vehicles.html#data-flow-example","title":"Data Flow Example","text":"<p>A vehicle (or any other entity for that matter) means different things to different teams and platforms.  </p> <p>The following diagram illustrates how a vehicle entity is seamlessly flowing between different platforms and teams within the distributor network.  </p> <p>Note</p> <p>The diagram is a simplified representation of the data flow and is only an arbitrary example.  Additionally, the vehicle entity here represents a Vehicle Model and not an individual vehicle.</p> <p></p> <p>In this way, Data Governance at the distributor ensures that data is centrally managed to maintain its quality and reliability, while the operational responsibilities are decentralized to improve efficiency and reduce redundancy.</p> <p>By adhering to these principles, the distributor maintains a robust data management strategy that supports its diverse and expansive operational needs.</p>"},{"location":"components/vehicles.html#vehicle-data-warehousing","title":"Vehicle Data Warehousing","text":"<p>Since each dealer (company) has its own DMS (Dealer Management System), a crucial part of the vehicle database is the data warehousing system.  </p> <p>Data from each dealer's DMS is periodically extracted, transformed, and loaded into the data warehouse.</p> <p></p>"},{"location":"components/services/claimable-items.html","title":"Claimable Items","text":"<p>Most Authorized Vehicles are usually sold with certain free services included. These services may vary depending on a number of factors and they are constantly subject to change. </p> <p>After activation, the service items can be claimed within a certain time window and the claiming dealer is reimbursed by the distributor.</p> <p>In addition to standard free service items, additional items belonging to various campaigns can be rewarded to vehicles. These items can come in the form of free services or discount vouchers that can be claimed in a similar way.</p> <p>In General, Claimable Items are any benefits, services, or offers associated with a vehicle that can be claimed by its owner. These items are often used to incentivize service visits or customer engagement. They may include:</p> <ul> <li>Free Services (such as 1,000 KM or 5,000 KM maintenance)</li> <li>Paid Services (such as Extended Warranty)</li> <li>Service Campaign Items (such as vouchers, event rewards, or loyalty-based incentives)</li> </ul> <p>The eligibility and claiming logic for all these items is unified under the Claimable Items framework.</p>"},{"location":"components/services/claimable-items.html#claimable-item-types","title":"Claimable Item Types","text":""},{"location":"components/services/claimable-items.html#free-services","title":"Free Services","text":"<p>Most Authorized vehicles come with a set of Free Services as part of their warranty package. These services vary based on several factors and are subject to frequent change.</p>"},{"location":"components/services/claimable-items.html#paid-services","title":"Paid Services","text":"<p>Similar to Free Services, Paid Services can also be assigned to vehicles. These are usually purchased by customers, for example to activate an Extended Warranty on either Authorized or Unauthorized vehicles.</p>"},{"location":"components/services/claimable-items.html#service-campaign-items","title":"Service Campaign Items","text":"<p>In addition to Free and Paid Services, Service Campaign Items may be rewarded to vehicles based on specific events or conditions. These may include:</p> <ul> <li>The vehicle is brought in for certain services or inspections.</li> <li>The vehicle is converted to special-purpose public/private vehicles (Taxi, Ambulance, Traffice Police, ...etc)</li> <li>The vehicle owner participates in a survey.</li> <li>The vehicle owner attends a special event.</li> <li>Loyalty Criteria (e.g., number of visits or service spend on the vehicle).</li> </ul> <p>Service Campaign Items can be Free or Discount-based and they may be provided as vouchers or other forms of rewards. </p>"},{"location":"components/services/claimable-items.html#claimable-item-management","title":"Claimable Item Management","text":"<p>The distributor maintains a central registry of all Claimable Items in the Services database. The following parameters define the eligibility and availability of each Claimable Item:</p> Parameter Description Item Type Free / Paid / Campaign Validity Period The duration after activation during which the item can be claimed. Rolling expiry logic is applied when multiple items are eligible Campaign Start/End Date The period during which the item can be rewarded to a vehicle. Different from Validity Period. Maximum Kilometerage Max KM on which the item can be claimed. Also used in sequencing items during the rolling expiry evaluation. Country Item availability can be limited by country. Company Item availability can be limited to specific dealers. Distributor / Dealer Contribution Cost-sharing ratio for Free/Campaign items. Must total 100%. Example: 30% / 70%. Models Katashiki or Variant codes (wildcard supported). E.g., TGN121L- targets all variants starting with that prefix. Brand For example: Toyota, Lexus, Daihatsu ...etc <p>Detailed Parameter Descriptions:</p>"},{"location":"components/services/claimable-items.html#item-type","title":"Item Type","text":"<p>Defines the classification of the item:</p> <ul> <li>Free: Included by default with the vehicle.</li> <li>Paid: Purchased separately by the customer.</li> <li>Campaign: Granted based on specific service campaigns.</li> </ul>"},{"location":"components/services/claimable-items.html#validity-period","title":"Validity Period","text":"<p>The duration during which the item is valid after activation. Supports rolling expiry logic - the next service item's activation is based on the previous service's expiry date (Sequencing is done based on the <code>Maximum Kilometerage</code>).</p> <p>Example: If a vehicle is sold on 2025-01-01:</p> <ul> <li>5,000 KM service (2 months validity) expires on 2025-03-01</li> <li>10,000 KM service (3 months validity) expires on 2025-06-01</li> </ul>"},{"location":"components/services/claimable-items.html#campaign-start-end-date","title":"Campaign Start / End Date","text":"<p>The period during which the item is granted to the vehicle - typically used for campaigns or limited-time offers.  Unlike the Validity Period, this controls when the item becomes available, not how long it stays claimable.</p> <p>Example: If a Free Service campaign runs from 2025-01-01 to 2025-01-07 and has a Validity Period of 3 months, only vehicles invoiced during this week will receive the item - then the customer can claim it within the next 3 months.</p>"},{"location":"components/services/claimable-items.html#maximum-kilometerage","title":"Maximum Kilometerage","text":"<p>The maximum odometer reading at which the item can be claimed.  Also used for sequencing items during the rolling expiry evaluation.</p>"},{"location":"components/services/claimable-items.html#country","title":"Country","text":"<p>Claimable Items can be restricted by country to account for regional service programs or operational differences.</p>"},{"location":"components/services/claimable-items.html#company","title":"Company","text":"<p>Restricts the item to specific dealers. Useful when a service is only available (offered) at selected service centers.</p>"},{"location":"components/services/claimable-items.html#distributor-dealer-contribution","title":"Distributor / Dealer Contribution","text":"<p>Specifies how the cost of Free or Campaign items is split between the distributor and the dealer. Both values must add up to 100%.  This is used for reimbursing dealers for the free service items that are claimed at their facilities.  </p> <p>Examples: </p> <ul> <li>Distributor 100% / Dealer 0%</li> <li>Distributor 30% / Dealer 70%</li> <li>Distributor 0% / Dealer 100%</li> </ul>"},{"location":"components/services/claimable-items.html#models","title":"Models","text":"<p>Specifies which vehicle models the item applies to, using Katashiki or Variant codes. Supports wildcard matching to group similar katashiki/variants under one pattern.</p> <p>Example: TGN121L- matches any variant starting with that prefix, such as:</p> <ul> <li>TGN121L-DTTHKV</li> <li>TGN121L-DTMSKV</li> <li>TGN121L-BTMSKV</li> </ul> <p>In addition to targeting, this parameter is also used to define the item cost per model. The same service may have different costs depending on the model - e.g., a 5,000 KM service for a <code>Hilux</code> will typically cost less than the same service for a <code>Land Cruiser</code>.</p>"},{"location":"components/services/claimable-items.html#brand","title":"Brand","text":"<p>Specifies the vehicle brand(s) applicable to the item.</p> <p>Example:</p> <ul> <li>Toyota</li> <li>Lexus</li> <li>Daihatsu</li> <li>Hino</li> </ul>"},{"location":"components/services/claimable-items.html#claimable-item-eligibility-claiming","title":"Claimable Item Eligibility &amp; Claiming","text":"<p>Eligible claimable items for a given vehicle is determined from two data sources:</p>"},{"location":"components/services/claimable-items.html#persistent-store","title":"Persistent Store","text":"<p>Items that are explicitly recorded and associated with a vehicle in the persistent store:</p> <ul> <li>Paid Items: When a <code>Paid Service</code> item is purchased. It's pushed to the VIN and stored persistently. Modifying the Claimable Item parameters or removing the item from the <code>Services Database</code> will not affect the items that are already pushed to a VIN.</li> <li>Claimed Items: When an item is claimed, it's also stored persistently.</li> </ul>"},{"location":"components/services/claimable-items.html#dynamic-evaluation","title":"Dynamic Evaluation","text":"<p>Evaluates Free Services and Service Campaign Items at runtime during a VIN lookup, ensuring up-to-date results based on current rules and data.</p> <p>Dynamic Evaluation</p> <p>This real-time process ensures that new or corrected data (e.g., pricing updates or backdated campaigns) become effective immediately after the parameters are updated in the Services database.</p>"},{"location":"components/services/claimable-items.html#eligibility-evaluation-flow","title":"Eligibility Evaluation Flow","text":"<ol> <li>Extract all eligible items for the vehicle in accordance with the parameters set on the service database.</li> <li>Load all items for the givine vehilce from the persistent store.</li> <li>Mark any claimed item as <code>Claimed</code>. </li> <li>Calculate the rolling expiry date for each eligible item and mark expired items as <code>Expired</code>.</li> <li>Mark items as <code>Cancelled</code> if a subsequent item is claimed before the current item is expired.</li> <li>Remaining items are marked as <code>Pending</code> and are available for claiming.</li> </ol>"},{"location":"components/services/claimable-items.html#service-item-claiming","title":"Service Item Claiming","text":"<p>Claiming is done via the Vehicle Lookup feature in the Hub.</p> <ul> <li>A unified view displays all claimable items, including Free, Paid, and Campaign-related.</li> <li>Each item shows its type, expiry, and claim status.</li> <li>Claiming an item requires attaching a service invoice - either scanned from a QR code or entered manually.</li> </ul>"},{"location":"components/services/intro.html","title":"Service Database","text":"<p>A centralized application for consolidating all service-related data and operations. The purpose of this application is to abstract the complexity of working with services and provide a clean API for other applications.  </p> <p>It includes, but is not limited to, the following:</p> <ol> <li>Service Information (Service Code, Service Type, Service Category, Service Price, etc.).</li> <li>Warranty System     \u2197.</li> <li>Menus (A collection of services grouped together as a package).</li> <li>Calendar &amp; Workshop Availability.</li> </ol>"},{"location":"components/services/warranty/warranty.html","title":"Warranty System","text":"<p>The warranty system acts as a hub between dealers, the distributor, and the manufacturer.  </p> <p>It allows dealers to submit warranty claims. The distributor can then review and approve these claims before forwarding them to the manufacturer for final approval.</p> <p></p>"},{"location":"components/vehicle-information/authorized.html","title":"Authorized (Official)","text":""},{"location":"components/vehicle-information/authorized.html#authorized-unauthorized-cars","title":"Authorized &amp; Unauthorized Cars","text":"<p>A car is considered \"Authorized\" or \"Official\" if it is imported by the official distributor for a specific geographic region.</p> <p>In contrast, cars not imported by the official distributor are considered \"Unauthorized\", \"Unofficial\", or \"Grey Imports\".</p>"},{"location":"components/vehicle-information/identifiers.html","title":"Identifiers","text":"<p>This section provides a top view of a vehicle, it's related information and processes.  </p>"},{"location":"components/vehicle-information/identifiers.html#vehicle-information","title":"Vehicle Information","text":"<p>Every single vehicle is indentified by a unique ID called a VIN (Vehicle Indentification Number).  Alongside the VIN, there are other information that identify a group of vehicles, the imporant identifiers are listed below</p>"},{"location":"components/vehicle-information/identifiers.html#priamry-identifier","title":"Priamry Identifier","text":""},{"location":"components/vehicle-information/identifiers.html#vin","title":"VIN","text":""},{"location":"components/vehicle-information/identifiers.html#overview","title":"Overview","text":"<p>VIN (Vehicle Identifiction Number) is a 17 digit string that's used to uniquely identify a vehicle (Example: MR0AX8CDXP4446478). VINs consists of 3 main components:   </p> <ol> <li>WMI (3 Characters) which is the World manufacturer identifier. (Example: MR0)</li> <li>VDS (6 Characters, the 6th character is the checksum digit) which is the Vehicle Descriptor Section. (Example: AX8CDX)</li> <li>VIS (8 Characters) which is the Vehicle Indicator Section. (Example: P4446478)</li> </ol>"},{"location":"components/vehicle-information/identifiers.html#validation","title":"Validation","text":"<p>The 9th digit of a VIN is Check digit. Using a simple mathmatical formula, you can validate most VINs more precisely than simply checking if the string is 17 digit. More information can be found on this Wiki Article.</p> VIN Validation Code Example C#TypeScript <pre><code>public static bool ValidateVin(string vin)\n{\n    if (string.IsNullOrWhiteSpace(vin) || vin.Length != 17)\n        return false;\n\n    var TransliterationTable = new Dictionary&lt;char, int&gt;();\n\n    TransliterationTable['0'] = 0;\n    TransliterationTable['1'] = 1;\n    TransliterationTable['2'] = 2;\n    TransliterationTable['3'] = 3;\n    TransliterationTable['4'] = 4;\n    TransliterationTable['5'] = 5;\n    TransliterationTable['6'] = 6;\n    TransliterationTable['7'] = 7;\n    TransliterationTable['8'] = 8;\n    TransliterationTable['9'] = 9;\n    TransliterationTable['A'] = 1;\n    TransliterationTable['B'] = 2;\n    TransliterationTable['C'] = 3;\n    TransliterationTable['D'] = 4;\n    TransliterationTable['E'] = 5;\n    TransliterationTable['F'] = 6;\n    TransliterationTable['G'] = 7;\n    TransliterationTable['H'] = 8;\n    TransliterationTable['J'] = 1;\n    TransliterationTable['K'] = 2;\n    TransliterationTable['L'] = 3;\n    TransliterationTable['M'] = 4;\n    TransliterationTable['N'] = 5;\n    TransliterationTable['P'] = 7;\n    TransliterationTable['R'] = 9;\n    TransliterationTable['S'] = 2;\n    TransliterationTable['T'] = 3;\n    TransliterationTable['U'] = 4;\n    TransliterationTable['V'] = 5;\n    TransliterationTable['W'] = 6;\n    TransliterationTable['X'] = 7;\n    TransliterationTable['Y'] = 8;\n    TransliterationTable['Z'] = 9;\n\n    var WeightTable = new int[] { 8, 7, 6, 5, 4, 3, 2, 10, 0, 9, 8, 7, 6, 5, 4, 3, 2 };\n\n    var sum = 0;\n\n    var valid = true;\n\n    for (var i = 0; i &lt; vin.Length; i++)\n    {\n        var character = vin[i];\n\n        if (!TransliterationTable.Keys.Contains(character))\n        {\n            valid = false;\n            break;\n        }\n\n        var value = TransliterationTable[character];\n\n        var weight = WeightTable[i];\n\n        var product = value * weight;\n\n        sum = sum + product;\n    }\n\n    var reminder = (sum % 11);\n\n    var reminderString = reminder.ToString();\n\n    if (reminder == 10)\n        reminderString = \"X\";\n\n    if (vin.Substring(8, 1) != reminderString)\n    {\n        valid = false;\n    }\n\n    return valid;\n}\n</code></pre> <pre><code>public static validateVin(vin:string): boolean {\n    var TransliterationTable = {\n        '0': 0,\n        '1': 1,\n        '2': 2,\n        '3': 3,\n        '4': 4,\n        '5': 5,\n        '6': 6,\n        '7': 7,\n        '8': 8,\n        '9': 9,\n\n        'A': 1,\n        'B': 2,\n        'C': 3,\n        'D': 4,\n        'E': 5,\n        'F': 6,\n        'G': 7,\n        'H': 8,\n\n        'J': 1,\n        'K': 2,\n        'L': 3,\n        'M': 4,\n        'N': 5,\n        'P': 7,\n        'R': 9,\n\n        'S': 2,\n        'T': 3,\n        'U': 4,\n        'V': 5,\n        'W': 6,\n        'X': 7,\n        'Y': 8,\n        'Z': 9\n    };\n\n    var WeightTable = [8, 7, 6, 5, 4, 3, 2, 10, 0, 9, 8, 7, 6, 5, 4, 3, 2];\n\n    var sum = 0;\n\n    var valid = true;\n\n    for (var i = 0; i &lt; vin.length; i++) {\n\n        var char = vin[i].toUpperCase();\n\n        var value = TransliterationTable[char];\n\n        if (value === undefined) {\n            valid = false;\n            break;\n        }\n\n        var weight = WeightTable[i];\n\n        var product = value * weight;\n\n        sum = sum + product;\n    }\n\n    var reminder = (sum % 11).toString();\n\n    if (reminder === '10')\n        reminder = 'X';\n\n    if (vin[8] != reminder) {\n        valid = false;\n    }\n\n    return valid;\n}\n</code></pre> <p>Note: You can use https://www.randomvin.com to generate random valid VINs for test purposes.</p>"},{"location":"components/vehicle-information/identifiers.html#vin-decoder","title":"VIN Decoder","text":"VIN Decoder Package <p>The following package is used to detect, validate and decode VINs. https://github.com/ShiftSoftware/ADP.VINDecode</p> <p>it provides SDKs for the following platforms/languages</p> <ul> <li>dotnet (C#)</li> <li>TypeScript</li> <li>Flutter (Not Implemented yet)</li> <li>Android (Not Implemented yet)</li> <li>iOS (Not Implemented yet)</li> </ul>"},{"location":"components/vehicle-information/identifiers.html#non-primary-vehicle-information","title":"Non Primary Vehicle Information","text":""},{"location":"components/vehicle-information/identifiers.html#variant","title":"Variant","text":"<p>A Variant is used to identify a group of vehicles (Example: 11371HB202301). Variants consist of 4 main components.</p> <p>Starting from the end of the code</p> <ol> <li>01: The last two digits: Always 01 and it's ignored.</li> <li>Year Model: The last 6 digits, excluding the constant 01 (Example: 2023).</li> <li>SFX: The last 8 digits, excluding Year Model and the Constant (Example: HB).</li> <li>Model Code: What remains after excluding SFX, Year Model, and the constant. (Example: 11371).</li> </ol>"},{"location":"components/vehicle-information/identifiers.html#katashiki","title":"Katashiki","text":"<p>A Katashiki is also used to identify a group of vehicles. But it's broader than variant (For example it does not change based on Year Model). (Example: TGN121L-DTTHKV).  </p> <p>Katashiki Codes consist of two components</p> <ol> <li>Service Model Code: The first component after seperating by a hyphen, and removing the L (Example: TGN121).                          </li> <li>The Second component is not used individually</li> </ol> <p>Note</p> <ul> <li>The \"L\" character in the first portion of Katashiki may not always be the last character. We remove it regardless of it's position. (Example: For F800LE-GQMFG, the Service Model Code is: F800E).</li> <li>Some Katashiki codes don't include an L character in the first portion. (Example: For SH2PEUA-DSW, the Service Model Code is: SH2PEUA)</li> </ul>"},{"location":"components/vehicle-information/identifiers.html#color","title":"Color","text":"<p>Every vehicle has a Color Code that identifies the Exterior Color of a car (Example: 040).</p>"},{"location":"components/vehicle-information/identifiers.html#trim","title":"Trim","text":"<p>Every vehicle has a Trim Code that identifies the Interios Color of a car (Example: 42).   </p>"},{"location":"components/vehicle-information/identifiers.html#brand-franchise","title":"Brand (Franchise)","text":"<p>An Automotive manufacturer company may produce vehicles under multiple brands. For example, as of 2022, the Toyota Motor Corporation produces vehicles under four brands: Daihatsu, Hino, Lexus and the namesake Toyota.  </p>"},{"location":"components/vehicle-information/safety-recalls.html","title":"Safety Recalls","text":""},{"location":"components/vehicle-information/safety-recalls.html#safety-recalls","title":"Safety Recalls","text":"<p>A recall is issued when a vehicle or part of a vehicle is found to be defective in a way that could affect the safety of the vehicle. </p> <p>In most cases, the manufacturer will provide a remedy for the defect, which may include repairing or replacing the defective part.  </p> <p>Vehicles that are subject to a recall can be looked up by their VIN using the Vehicle Lookup Feature.</p>"},{"location":"components/vehicle-information/safety-recalls.html#recalls-on-authorized-vehicles","title":"Recalls on Authorized Vehicles","text":"<p>The distributor has precise recall records for Authorized Vehicles, making the lookup process straightforward by simply checking the database for the VIN.</p> <p>In addition to identifying whether a vehicle is affected by a recall, the system also determines whether the recall has been repaired or still requires action. This is done through a multi-source repair status check:</p> <ul> <li>Inline Data: If the recall record itself directly indicates that the repair has been completed, this information is used.</li> <li>Warranty Claims: The system also checks warranty claims (if available) to confirm completion. This is determined by validating the Labor Operation Code and the presence of the Campaign Code in the warranty notes.</li> <li>Labor Lines: As a final step, the system reviews labor lines retrieved from the DMS (if available) for evidence that the recall-related work has been performed.</li> </ul> <p>By combining these sources, the system ensures the most accurate status for each recall. This helps service teams and customers know not just whether a vehicle is affected, but also whether the recall has already been addressed.</p>"},{"location":"components/vehicle-information/safety-recalls.html#recalls-on-unauthorized-vehicles","title":"Recalls on Unauthorized Vehicles","text":"<p>In most cases, the distributor does not have precise recall records for Unauthorized Vehicles. However, the distributor may be able to check the VIN against the Manufacturer's system either through an integration or manually.</p>"},{"location":"components/vehicle-information/safety-recalls.html#manual-manufacturer-system-check","title":"Manual Manufacturer System Check","text":"<p>In the event that the distributor does not have an integration with the Manufacturer's system, the lookup process is as follows:</p> <ol> <li>The user requests a recall check for an unauthorized vehicle and the VIN is logged as a ticket.</li> <li>The distributor team will need to manually check the VIN against the manufacturer's system and update the ticket with the recall details.</li> <li>After resolving the ticket, the results will be communicated to the user who made the request via email or other mediums.</li> </ol>"},{"location":"components/vehicle-information/safety-recalls.html#integration-with-manufacturers-system","title":"Integration with Manufacturer's System","text":"<p>In the event that the distributor has an integration with the Manufacturer's system, the lookup process is as follows:</p> <ol> <li>The user requests a recall check for an unauthorized vehicle and the VIN is logged.</li> <li>The system will automatically check the VIN against the manufacturer's system via and API call.</li> <li>The Manufacturer's system may respond in one of the following ways:<ol> <li>Provide a list of recalls associated with the VIN.      In this case, the user will be presented with all the details of the recalls, including the recall number, description, and repair status.</li> <li>Provide a yes/no response indicating whether the VIN is subject to a recall.     In this case, a ticket will be created and the distributor team will need to manually check the VIN against the manufacturer's system and update the ticket with the recall details.</li> </ol> </li> </ol>"},{"location":"components/vehicle-information/service-history.html","title":"Service History","text":"<p>Services performed on a vehicle at any authorized dealer are recorded in the dealer's DMS (Dealer Management System).   </p> <p>Common Services include, but are not limited to:</p> <ul> <li>Periodic Maintenance</li> <li>Checkups and General Repairs</li> </ul> <p>Since data from all dealers are synchronized to the centralized Data Warehouse, the service history of a vehicle is available in the Vehicle Lookup Feature.</p>"},{"location":"components/vehicle-information/warranty.html","title":"Warranty","text":""},{"location":"components/vehicle-information/warranty.html#standard-warranty","title":"Standard Warranty","text":"<p>Almost all authorized vehicles come with a standard warranty that is usually activated from the date of sale to the end customer (Invoice Date).</p> <p>Note</p> <p>The Warranty Activation depends on the End Customer's Invoice Date. This should not to be confused with any of the following or other invoice dates of a vehicle:   <ul> <li>Manufacturer to Distributor Invoice Date.</li> <li>Distributor to Dealer Invoice Date.</li> <li>Dealer To Sub-Dealer or Other Dealer Invoice Date.</li> <li>Dealer (Or Sub-Dealer) to 3rd Party Partners (Brokers) Inovice Date.</li> </ul></p> <p>Additionally, there are cases where the warranty activation date does not exactly match the invoice date. For example, there may be a delay in delivering the vehcile to the end customer.</p>"},{"location":"components/vehicle-information/warranty.html#extended-warranty","title":"Extended Warranty","text":"<p>Customers have the option to extend their warranty by buying extended warranty packages.</p>"},{"location":"generated/Models/Enums/Currencies.html","title":"Currencies","text":"Value Summary NotSpecified USD IQD UZS TMT TJS"},{"location":"generated/Models/Invoice/InvoiceModel.html","title":"InvoiceModel","text":"<p>A Service Invoice or a Counter Sale Parts Invoice.</p> Property Summary id <code>string</code> OrderDocumentNumber <code>string</code> CompanyID <code>long?</code> CompanyHashID <code>string</code> BranchID <code>long?</code> BranchHashID <code>string</code> VIN <code>string</code> InvoiceDate <code>DateTime?</code> ServiceDetails <code>string</code> Mileage <code>int?</code> AccountNumber <code>string</code> CustomerAccountNumber <code>string</code> CustomerID <code>string</code> SaleType <code>string</code> InvoiceNumber <code>string</code> InvoiceCurrency <code>Currencies?</code> LaborLineCount <code>int?</code> PartLineCount <code>int?</code> NextServiceDate <code>DateTime?</code> ItemType <code>string</code> InvoiceStatus <code>string</code>"},{"location":"generated/Models/Part/CatalogPartModel.html","title":"Catalog Part","text":"<p>Catalog Part refers to a specific part in the Parts Catalog.  It is used to define the properties and information of a part.</p> Property Summary ID <code>string</code> The unique identifier for the catalog part. If an ID is not available, then the part number should be used as the ID. PartNumber <code>string</code> Each part has a unique part number that is used to identify it in the catalog and other related documents/systems. GenuinePartNumber <code>bool</code> Indicates whether the part is a Genuine Part Number PartName <code>string</code> The name of the part as it appears in the catalog. ProductGroup <code>string</code> The product group code to which the part belongs. ProductGroupDescription <code>string</code> The description of the product group to which the part belongs. BinType <code>string</code> The type of the bin in which the part is stored. DistributorPurchasePrice <code>decimal?</code> The purchase price that the distributor pays for the part. ProductCode <code>string</code> The product code that is used to identify the part in the catalog. PNC <code>string</code> The Product Number Code (PNC) Length <code>decimal?</code> The length of the part. Width <code>decimal?</code> The width of the part. Height <code>decimal?</code> The height of the part. NetWeight <code>decimal?</code> The weight of the part. CubicMeasure <code>decimal?</code> The cubic measure of the part. GrossWeight <code>decimal?</code> The gross weight of the part. Origin <code>string</code> The country of origin of the part. SupersededTo <code>IEnumerable&lt;PartSupersessionModel&gt;</code> A list of all the Supersessions that the part has. SupersededFrom <code>IEnumerable&lt;PartSupersessionModel&gt;</code> A list of all Supersessions Where this part is the superseding part. LocalDescription <code>string</code> The localized description of the part. HSCode <code>string</code> The Harmonized System (HS) code for the part. CountryData <code>IEnumerable&lt;PartCountryDataModel&gt;</code> Per Country data for the part."},{"location":"generated/Models/Part/ManufacturerPartLookupModel.html","title":"ManufacturerPartLookupModel","text":"Property Summary BranchID <code>long?</code> BranchHashID <code>string</code> CompanyID <code>long?</code> CompanyHashID <code>string</code> UserID <code>long?</code> UserEmail <code>string?</code> PartNumber <code>string</code> Quantity <code>decimal</code> OrderType <code>ManufacturerOrderType</code> LogId <code>string?</code> Status <code>ManufacturerPartLookupStatus</code> ManufacturerResult <code>IEnumerable&lt;KeyValuePair&lt;string, string&gt;&gt;?</code>"},{"location":"generated/Models/Part/OrderPartLineModel.html","title":"Order Part Line","text":"<p>Refers to a Part Line on an Order (This might be a Job Card on Workshop Module, or a Counter Sale on Parts Module).</p> Property Summary LineID <code>string</code> The unique identifier of the Order Line. ItemStatus <code>string</code> OrderStatus <code>string</code> InvoiceStatus <code>string</code> InvoiceDate <code>DateTime?</code> The date at which this line was invoiced. OrderDocumentNumber <code>string</code> The Order Number associated with this line. (Job Card Number, Counter Sale Order Number) InvoiceNumber <code>string</code> The Invoice Number associated with this part line. ParentInvoiceNumber <code>string</code> The Parent Invoice Number associated with this part line. (In case of Credit Notes or Debit Notes) InvoiceCurrency <code>Currencies?</code> The Invoice Currency OrderQuantity <code>decimal?</code> The quantity of the part line that ordered. SoldQuantity <code>decimal?</code> The quantity of the part line that sold. SaleType <code>string</code> The type of sale. (e.g. Internal, Bulk, Retail, etc.) PackageCode <code>string</code> The Package Code in case this part line is a package item. ExtendedPrice <code>decimal?</code> The final price of this line item after accounting for quantity, discounts, and any applicable taxes or additional charges PartNumber <code>string</code> The uniqe Part Number of the Catalog Part. GenuinePartNumber <code>bool</code> Indicates whether the part is a Genuine Part Number Location <code>string</code> The Warehouse/Location Identifier where the transaction happens. AccountNumber <code>string</code> The Account Number from the Accounting System. CustomerAccountNumber <code>string</code> The Customer Account Number from the Accounting System. CustomerID <code>string</code> The Company Specific Customer ID. GoldenCustomerID <code>string</code> The Centralized unique Golden Customer ID. Department <code>string</code> The Department Code/ID. VIN <code>string</code> The Vehicle Identification Number (VIN) of the vehicle associated with this part line. LoadDate <code>DateTime?</code> The date at which this line was loaded into the Order Document. PostDate <code>DateTime?</code> The date at which this line was posted. This could mean (Job Completed, Part Dispatched, Vehicle Allocated, etc. based on the type of the Order Document). CompanyHashID <code>string</code> The Company Hash ID from the Identity System. BranchHashID <code>string</code> The Branch Hash ID from the Identity System. IntegrationID <code>string</code> IntegrationSuccessStatus <code>bool</code> A boolean flag indicating the completion of system to system Integration IdempotencyKey <code>Guid?</code> A Unique key generated by ADP and used to ensure that repeated external posting of the same entry does not result in duplicate records. NumberOfLaborLines <code>int</code> The number of corresponding labor lines associated with the parent order of this line. CompanyIntegrationID <code>string</code> An External Identifier that can be used for system to system Integration BranchIntegrationID <code>string</code> An External Identifier that can be used for system to system Integration"},{"location":"generated/Models/Part/PartCountryDataModel.html","title":"Part Country Data","text":"<p>Represents the country-specific information for a part.</p> Property Summary CountryHashID <code>string</code> The Country Hash ID from the Identity System. HSCode <code>string</code> Country-specific Harmonized System (HS) code for the part. RegionPrices <code>IEnumerable&lt;RegionPriceModel&gt;</code> Region-specific price information for the part."},{"location":"generated/Models/Part/PartSupersessionModel.html","title":"Part Supersession","text":"<p>Represents a part's supersession information. A part can be superseded by another part.</p> Property Summary PartNumber <code>string</code> The part number of the superseding part. SupersessionCode <code>int?</code>"},{"location":"generated/Models/Part/RegionPriceModel.html","title":"Per Region Price","text":"<p>Used to define the price of a part in a specific region.</p> Property Summary RegionHashID <code>string</code> The Region Hash ID from the Identity System. RetailPrice <code>decimal?</code> The Retail Price of the part in the region. PurchasePrice <code>decimal?</code> The retailer purchase price of the part in the region. (Alos known as the distributor sell price) WarrantyPrice <code>decimal?</code> The warranty price of the part in the region. (As reimbursed by the distributor)"},{"location":"generated/Models/Part/StockPartFirstReceiveDateModel.html","title":"StockPartFirstReceiveDateModel","text":"<p>Refers to a first receive date Part in a Stock (Warehouse), if provided separately</p> Property Summary PartNumber <code>string</code> The Unique Part Number GenuinePartNumber <code>bool</code> Indicates whether the part is a Genuine Part Number Location <code>string</code> The Warehouse/Location Identifier where the part is stored. FirstReceivedDate <code>DateTimeOffset?</code> CompanyHashID <code>string</code> The Company Hash ID from the Identity System. IntegrationID <code>string</code> An External Identifier that can be used for system to system Integration IdempotencyKey <code>Guid?</code> A Unique key generated by ADP and used to ensure that repeated external posting of the same entry does not result in duplicate records. IntegrationSuccessStatus <code>bool</code> A boolean flag indicating the completion of system to system Integration"},{"location":"generated/Models/Part/StockPartModel.html","title":"Stock Part","text":"<p>Refers to a Part in a Stock (Warehouse)</p> Property Summary PartNumber <code>string</code> The Unique Part Number GenuinePartNumber <code>bool</code> Indicates whether the part is a Genuine Part Number Location <code>string</code> The Warehouse/Location Identifier where the part is stored. AvailableQuantity <code>decimal?</code> The current AvailableQuantity of the part in the stock. OnHandQuantity <code>decimal?</code> The current on-hand quantity of the part in the stock OnOrderQauntity <code>decimal?</code> InventoryDate <code>DateTimeOffset?</code> LastSoldDate <code>DateTimeOffset?</code> LastArrivedDate <code>DateTimeOffset?</code> LastPurchasedDate <code>DateTimeOffset?</code> FirstReceivedDate <code>DateTimeOffset?</code> SaleType <code>string</code> The type of sale. (e.g. Internal, Bulk, Retail, etc.) CompanyHashID <code>string</code> The Company Hash ID from the Identity System. IntegrationID <code>string</code> An External Identifier that can be used for system to system Integration IdempotencyKey <code>Guid?</code> A Unique key generated by ADP and used to ensure that repeated external posting of the same entry does not result in duplicate records. IntegrationSuccessStatus <code>bool</code> A boolean flag indicating the completion of system to system Integration CatalogPart <code>CatalogPartModel</code> Catalog part associated with this stock part"},{"location":"generated/Models/Service/OrderLaborLineModel.html","title":"Order Labor Line","text":"<p>Refers to a Labor Line on an Order (Typically a Job Card on Workshop Module).</p> Property Summary LineID <code>string</code> The unique identifier of the Labor Line. InvoiceDate <code>DateTime?</code> The date at which this line was invoiced. OrderDocumentNumber <code>string</code> The Order Number associated with this line. (Job Card Number, Counter Sale Order Number) JobDescription <code>string</code> A general description of the parent order/job associated with this labor line. InvoiceNumber <code>string</code> The Invoice Number associated with this labor line. ParentInvoiceNumber <code>string</code> The Parent Invoice Number associated with this labor line. (In case of Credit Notes or Debit Notes) InvoiceCurrency <code>Currencies?</code> The Invoice Currency OrderQuantity <code>decimal?</code> The quantity of the labor line that ordered. SoldQuantity <code>decimal?</code> The quantity of the labor line that sold. SaleType <code>string</code> The type of sale. (e.g. Internal, Bulk, Retail, etc.) PackageCode <code>string</code> The Package Code in case this labor line is a package item. ExtendedPrice <code>decimal?</code> The final price of this line item after accounting for quantity, discounts, and any applicable taxes or additional charges LaborCode <code>string</code> The unique Labor/Operation Code. Typically from the Manufacturer's Service Catalog. ServiceCode <code>string</code> The service code associated with this line. Typically a distributor level code. ServiceDescription <code>string</code> The description associated with this line. Typically a free text or a distributor/dealer level description of the labor operation performed. AccountNumber <code>string</code> The Account Number from the Accounting System. CustomerAccountNumber <code>string</code> The Customer Account Number from the Accounting System. CustomerID <code>string</code> The Company Specific Customer ID. GoldenCustomerID <code>string</code> The Centralized unique Golden Customer ID. Department <code>string</code> The Department Code/ID. VIN <code>string</code> The Vehicle Identification Number (VIN) of the vehicle associated with this labor line. LoadDate <code>DateTime?</code> The date at which this line was loaded into the Order Document. PostDate <code>DateTime?</code> The date at which this line was posted. This could mean (Job Completed, Part Dispatched, Vehicle Allocated, etc. based on the type of the Order Document). CompanyHashID <code>string</code> The Company Hash ID from the Identity System. BranchHashID <code>string</code> The Branch Hash ID from the Identity System. InvoiceStatus <code>string</code> ItemStatus <code>string</code> OrderStatus <code>string</code> NextServiceDate <code>DateTime?</code> The date for the next scheduled service of the vehicle associated with this labor line. NumberOfPartLines <code>int</code> The number of corresponding part lines associated with the parent order of this line. CompanyIntegrationID <code>string</code> An External Identifier that can be used for system to system Integration BranchIntegrationID <code>string</code> An External Identifier that can be used for system to system Integration Odometer <code>int?</code> The odometer reading of the vehicle at the time this job was opened."},{"location":"integrations/intro.html","title":"Integrations","text":"<p>Being the centralized platform between the distributor, its dealers, and customers. Integrations is in the heart of the ADP.</p>"},{"location":"integrations/intro.html#connectors","title":"Connectors","text":"<p>The following are the different types of integration connectors that can be utilized by ADP:</p> <ul> <li>Direct Database (SQL, or other types of databases).</li> <li>Restful APIs.</li> <li>Parquet, CSV, JSON, XML, or other file-based data exchange formats.</li> </ul>"},{"location":"integrations/intro.html#direct-database-connector","title":"Direct Database Connector","text":"<p>The distributor obtains and stores a connection string of each dealer's DMS database securely in a cloud vault. This connector allows the ADP to directly query the dealer's DMS database to fetch data periodically.</p> <p>Warning</p> <p>Writing to the dealer's DMS databas is typically not required. It's preferred that dealers share connection string with read-only access.</p>"},{"location":"integrations/intro.html#restful-api-connector","title":"Restful API Connector","text":"<p>This could come in two modes:</p> <ul> <li>Push by DMS (Batch): The distributor provides a set of RESTful APIs that the dealers can use to push data batches to the ADP.</li> <li>Pull by ADP (Batch): The dealer's DMS system provides a set of RESTful APIs that the ADP can use to pull data batches from the dealer's DMS.</li> </ul> <p>Note</p> <p>Webhooks or Event Notifications: </p> <p>For push based integration, the dealer's system can trigger real-time updates to the ADP when a change occurs, eliminating the need for periodic polling.</p> <p>However, this by itself is not sufficient due to the following reasons:</p> <ul> <li>Initial Sync: While it's technically possible to use webhooks for initial sync, it may not be practical as webhooks are typically used to push a single record at a time. And the initial sync may involve a large number of records.</li> <li>Data Loss: If the webhook trigger fails for any reason, the ADP may miss important updates. If no other means of data transfer is available, then there should be a way to re-trigger (retry) the missed push indefinitely until the record is successfully pushed.</li> <li>Data Reinitialization: There are cases when full data reinitialization is required. For example, if a dealer's Database or ADP database is structurally changed, or if the data is corrupted. In such cases, the dealer's DMS system should be able to reinitialize the data in ADP by pushing all records again.</li> </ul>"},{"location":"integrations/intro.html#file-based-connector","title":"File-based Connector","text":"<p>The dealer's DMS system can periodically export data in Parquet, CSV, JSON, or XML format to a specified local or remote location. </p> <p>These files can be synced to ADP cloud using a file sync tool like Azure File Sync. ADP will then process these files to update its database.</p>"},{"location":"integrations/intro.html#data-synchronization","title":"Data Synchronization","text":"<p>Efficient data synchronization is critical to ensure the ADP platform remains up-to-date without loading and processing redundant information. Rather than syncing the entire dataset during each integration cycle, ADP supports several techniques to fetch only newly added or modified data.  </p>"},{"location":"integrations/intro.html#sync-strategies","title":"Sync Strategies","text":""},{"location":"integrations/intro.html#timestamps-last-updated-fields","title":"Timestamps / Last Updated Fields","text":"<p>Records that include a last_modified, updated_at, or similar timestamp field can be filtered to return only those changed since the last successful sync.  This takes different forms depending on the connector type:</p> <ul> <li>Direct Database: The SQL query can be modified to include a WHERE clause that filters records based on the last_updated timestamp.</li> <li>Restful API:<ul> <li>Push by DMS: The dealer's DMS system should store the last successful push timestamp and only push records that have been modified/created since that timestamp.</li> <li>Pull by ADP: ADP stores the last successful pull timestamp and only requests records that have been modified/created since that timestamp.</li> </ul> </li> <li>File-based: <ul> <li>The dealer's DMS system can dump records that have been modified/created since the last successful dump and store them in a file containing the current batch of records. (company_a_part_stock_2025_05_13_12_00_00.csv).</li> <li>The dealer's DMS system can dump all records to a file and replace it on every dump. (company_a_part_stock.csv). ADP will handle processing the file and only updating the records that have been modified/created since the last successful dump. (This is done internally by doing a git diff between the last dump and the current dump).</li> </ul> </li> </ul>"},{"location":"integrations/parts.html","title":"Parts Integration","text":"<p>It's typical that each company has a dedicated parts database.</p>"},{"location":"integrations/parts.html#various-part-databases","title":"Various Part Databases","text":"<ul> <li>The Manufacturer: has a parts database that contains all the genine parts. This dataset is provided by the manufacturer to the distributor and it is updated regularly.</li> <li>The Distributor: has a parts database that contains all the genuine parts received from the manufacturer plus other 3rd party parts that are provided by other manufacturers or the distributor itself.</li> <li>The Dealers: have a parts database that contains a subset of the genuine and 3rd party parts received from the distributor plus other parts that are not provided by the distributor.</li> </ul>"},{"location":"integrations/parts.html#master-data-management-mdm","title":"Master Data Management (MDM)","text":"<p>As a Master Data Management (MDM) system, ADP keeps a single Golden Record (GR) for each part.   </p> <p>The GRs are typically created by the distributor by merging part and pricing information from the manufacturer and other 3rd party parts.   </p>"},{"location":"integrations/parts.html#dealer-parts-catalog","title":"Dealer Parts Catalog","text":"<p>ADP Regularly pulls dealer parts catalogs and creates Dealer-Specific GRs for parts that are not already available.</p>"},{"location":"integrations/sync-agent/index.html","title":"ADP Sync Agent","text":"<p>The ADP Sync Agent is a NuGet package that provides a robust, reusable framework for building scheduled or event-driven data synchronization pipelines. It standardizes the process of moving and transforming data between various systems with a focus on reliability, performance, and maintainability.</p> <p>The Sync Agent ships with built-in adapters for common data sources and destinations, and exposes clean interfaces for implementing custom adapters when needed. This makes it easy to integrate the agent into a wide variety of enterprise data flow scenarios.</p>"},{"location":"integrations/sync-agent/index.html#package","title":"Package","text":"Package ID <code>ShiftSoftware.ADP.SyncAgent</code> Target Framework <code>.NET 10</code>"},{"location":"integrations/sync-agent/index.html#key-capabilities","title":"Key Capabilities","text":"Capability Description Standardized Adapters Ready-to-use, tested adapters for CSV, EF Core, Azure Cosmos DB, and DuckDB \u2014 eliminating the need for repetitive, fragile integrations. Efficient Memory Management Optimized for large datasets with careful memory handling to prevent <code>OutOfMemoryException</code> and other issues common in ad-hoc pipelines. Resilience &amp; Fault Tolerance Configurable retry policies, batch-level error handling, and multiple retry strategies ensure transient failures do not corrupt data. Atomic Execution A pipeline run is only marked successful when every critical step completes \u2014 read, transform, write, and mark-as-synced. Partial results are controlled by the developer. Extensibility Developers can implement custom Data Adapters and inline or reusable mapping functions to integrate with any system. Logging &amp; Progress A pluggable logger interface provides real-time progress tracking, elapsed time, remaining timeout, and per-batch status for operational visibility."},{"location":"integrations/sync-agent/index.html#why-not-ad-hoc-pipelines","title":"Why Not Ad-Hoc Pipelines?","text":"<p>In many enterprise environments, data synchronization is handled through numerous ad-hoc pipelines built by different teams, often with inconsistent quality, reliability, and scalability.</p> <p>These pipelines are prone to critical issues \u2014 not necessarily due to negligence, but because the application development teams building them may lack the budget, time, or immediate need to fully account for the complexities and best practices of reliable data integration.</p> <p>Their focus is typically on delivering core application functionality, not the underlying data transport.</p> <p>As a result, many of the pitfalls associated with data pipelines \u2014 such as partial failures, inconsistent data, and performance bottlenecks \u2014 go unnoticed during early development and testing phases.</p> <p>Unfortunately, these issues often surface only in real-world scenarios under heavy load, when inaccurate or incomplete data can cause significant damage and become costly to resolve.</p> <p>Common issues with ad-hoc pipelines:</p> <ul> <li>Memory leaks during high-volume processing</li> <li>Data inconsistency from partial failures</li> <li>Lack of retries or recovery mechanisms</li> <li>Difficulty in maintenance and observability</li> </ul> <p>The ADP Sync Agent addresses these challenges with a consistent, heavily tested, and well-structured approach.</p>"},{"location":"integrations/sync-agent/index.html#documentation","title":"Documentation","text":"Section Description Architecture The Sync Engine pipeline lifecycle, action ordering, and batch processing model. Data Adapters Built-in source and destination adapters \u2014 CSV, EF Core, Cosmos DB, and DuckDB. Configuration Reference for all configuration types and options. Resilience &amp; Fault Tolerance Retry strategies, batch retry, and error handling. Logging &amp; Monitoring Pluggable loggers, progress indicators, and operational visibility. Getting Started Quick start guide with dependency injection setup and end-to-end examples."},{"location":"integrations/sync-agent/index.html#preview","title":"Preview","text":"<p>In most cases the Sync Agent runs in the background. But when a UI is needed, the Sync Agent provides tools for real-time progress visualization.</p>"},{"location":"integrations/sync-agent/architecture.html","title":"Architecture","text":"<p>The Sync Engine is the core orchestrator of every data synchronization pipeline in the ADP Sync Agent. It manages the full lifecycle of a sync operation \u2014 from preparation through batch processing to completion \u2014 with built-in support for retries, cancellation, and progress tracking.</p>"},{"location":"integrations/sync-agent/architecture.html#pipeline-lifecycle","title":"Pipeline Lifecycle","text":"<p>Every pipeline execution follows a well-defined sequence of stages. Understanding this lifecycle is key to building reliable and predictable sync pipelines.</p> <pre><code>flowchart TD\n    A[Preparing] --&gt;|Succeeded| B[Action Loop]\n    A --&gt;|Skipped| S[Succeeded]\n    A --&gt;|Failed| F[Failed]\n\n    B --&gt; C[ActionStarted]\n    C --&gt;|Continue| D[SourceTotalItemCount]\n    C --&gt;|Stop| AC[ActionCompleted]\n    D --&gt; E[Batch Loop]\n\n    E --&gt; BS[BatchStarted]\n    BS --&gt; G[GetSourceBatchItems]\n    G --&gt; H[Mapping]\n    H --&gt; I[StoreBatchData]\n    I --&gt;|Success| BC[BatchCompleted]\n    I --&gt;|Failure| BR[BatchRetry]\n    BR --&gt;|Retry| G\n    BR --&gt;|Skip| BC\n    BR --&gt;|Stop| AC\n    BC --&gt;|Next Batch| E\n    BC --&gt;|All Batches Done| AC\n\n    AC --&gt;|Next Action| B\n    AC --&gt;|All Actions Done| S\n\n    S --&gt; FN[Finished]\n    F --&gt; FN</code></pre>"},{"location":"integrations/sync-agent/architecture.html#stages-in-detail","title":"Stages in Detail","text":""},{"location":"integrations/sync-agent/architecture.html#preparing","title":"Preparing","text":"<p>The first stage of the pipeline. This is where adapters perform initialization work \u2014 such as loading and comparing CSV files or setting up database connections.</p> <p>The preparing stage can return one of three results:</p> Result Behavior <code>Succeeded</code> Continue to the action loop. <code>Skipped</code> Mark the pipeline as successful without processing any data (e.g., no changes detected). <code>Failed</code> Mark the pipeline as failed immediately."},{"location":"integrations/sync-agent/architecture.html#action-loop","title":"Action Loop","text":"<p>A sync pipeline processes data through one or more actions. Each action represents a category of data operation. The default action execution order is:</p> <ol> <li>Delete \u2014 Remove obsolete records from the destination.</li> <li>Update \u2014 Modify existing records in the destination.</li> <li>Add \u2014 Insert new records into the destination.</li> </ol> <p>This order is configurable. The available action types are:</p> Action Type Description <code>Add</code> Insert new records. <code>Update</code> Update existing records. <code>Delete</code> Remove records. <code>Upsert</code> Insert or update (used by Cosmos DB adapter). <p>Action Execution Order</p> <p>The default order (Delete \u2192 Update \u2192 Add) ensures that stale data is cleaned up before new data arrives, reducing the risk of conflicts. You can customize this order via the <code>Configure</code> method.</p>"},{"location":"integrations/sync-agent/architecture.html#actionstarted","title":"ActionStarted","text":"<p>Called at the beginning of each action. Return <code>true</code> to proceed with the action, or <code>false</code> to skip it entirely.</p> <p>This is a good place for adapters to open file readers, prepare queries, or perform action-specific initialization.</p>"},{"location":"integrations/sync-agent/architecture.html#sourcetotalitemcount","title":"SourceTotalItemCount","text":"<p>An optional stage where the source adapter can report the total number of items to be processed for the current action. This enables:</p> <ul> <li>Accurate batch count calculation.</li> <li>Progress percentage tracking.</li> <li>Estimated time remaining.</li> </ul> <p>If not provided, the engine runs in streaming mode \u2014 processing batches until the source returns no more items.</p>"},{"location":"integrations/sync-agent/architecture.html#batch-loop","title":"Batch Loop","text":"<p>The core of the pipeline. Data is processed in configurable batches to manage memory and enable granular retry.</p> <p>Each batch goes through the following stages:</p>"},{"location":"integrations/sync-agent/architecture.html#batchstarted","title":"BatchStarted","text":"<p>Called before each batch. Return <code>true</code> to process the batch, or <code>false</code> to stop the pipeline.</p>"},{"location":"integrations/sync-agent/architecture.html#getsourcebatchitems","title":"GetSourceBatchItems","text":"<p>Retrieves the next batch of items from the data source. On retry, the engine passes the previous batch items to avoid re-reading from the source.</p>"},{"location":"integrations/sync-agent/architecture.html#mapping","title":"Mapping","text":"<p>Transforms source items into destination items. Two mapping modes are available:</p> <ul> <li>Simple Mapping \u2014 A function that receives source items and the action type, returns destination items. On retry, previously mapped items are reused automatically.</li> <li>Advanced Mapping \u2014 Full access to the <code>SyncMappingInput</code> including previous mapped items and retry status, giving the developer complete control.</li> </ul>"},{"location":"integrations/sync-agent/architecture.html#storebatchdata","title":"StoreBatchData","text":"<p>Writes the mapped items to the destination. Returns a <code>SyncStoreDataResult</code> that categorizes items as:</p> Category Description <code>SucceededItems</code> Items that were written successfully. <code>FailedItems</code> Items that failed to write. <code>SkippedItems</code> Items that were intentionally skipped. <p>If the result contains failed items, a <code>RetryException</code> can be set to trigger the retry mechanism.</p>"},{"location":"integrations/sync-agent/architecture.html#batchretry","title":"BatchRetry","text":"<p>Called when a batch fails. The developer can choose a retry strategy:</p> Strategy Behavior <code>RetryAndStopAfterLastRetry</code> Retry up to <code>MaxRetryCount</code>, then stop the entire action. (Default) <code>RetryAndContinueAfterLastRetry</code> Retry up to <code>MaxRetryCount</code>, then skip the failed batch and continue. <code>Skip</code> Skip the failed batch immediately and continue to the next. <code>Stop</code> Stop the entire action immediately."},{"location":"integrations/sync-agent/architecture.html#batchcompleted","title":"BatchCompleted","text":"<p>Called after a batch is successfully stored (or after the last retry with <code>RetryAndContinueAfterLastRetry</code>). Return <code>true</code> to continue, or <code>false</code> to trigger a retry.</p> <p>This is where source adapters typically mark data as synced \u2014 for example, updating a <code>LastSynced</code> timestamp on processed records.</p>"},{"location":"integrations/sync-agent/architecture.html#actioncompleted","title":"ActionCompleted","text":"<p>Called after all batches for an action are processed. Return <code>true</code> to mark the action as successful, or <code>false</code> to mark it as failed.</p>"},{"location":"integrations/sync-agent/architecture.html#succeeded-failed","title":"Succeeded / Failed","text":"<p>Called after all actions complete. <code>Succeeded</code> is invoked if all actions passed. <code>Failed</code> is invoked if any action failed or an unhandled exception occurred.</p>"},{"location":"integrations/sync-agent/architecture.html#finished","title":"Finished","text":"<p>Always called at the end of a pipeline execution, regardless of outcome. This is the place for cleanup \u2014 closing file handles, disposing resources, or deleting temporary directories.</p>"},{"location":"integrations/sync-agent/architecture.html#cancellation-timeouts","title":"Cancellation &amp; Timeouts","text":"<p>Every pipeline execution is governed by an <code>OperationTimeoutInSeconds</code> (default: 300 seconds). A <code>CancellationToken</code> is automatically created and passed to every stage. When the timeout expires, the pipeline raises an <code>OperationCanceledException</code>.</p> <p>The cancellation token is available to all adapters and custom functions via <code>SyncFunctionInput.CancellationToken</code>.</p>"},{"location":"integrations/sync-agent/architecture.html#single-type-vs-dual-type-pipelines","title":"Single-Type vs. Dual-Type Pipelines","text":"<p>The Sync Engine supports two generic patterns:</p> <ul> <li><code>SyncEngine&lt;T&gt;</code> \u2014 Source and destination share the same type. Useful when the data shape is identical (e.g., syncing between two databases with the same schema).</li> <li><code>SyncEngine&lt;TSource, TDestination&gt;</code> \u2014 Source and destination use different types. This is the common case when transformation is required.</li> </ul>"},{"location":"integrations/sync-agent/architecture.html#fluent-configuration","title":"Fluent Configuration","text":"<p>The Sync Engine uses a fluent API for setup:</p> <pre><code>var engine = new SyncEngine&lt;SourceModel, DestModel&gt;();\n\nengine\n    .Configure(batchSize: 500, maxRetryCount: 3, operationTimeoutInSeconds: 600)\n    .SetupPreparing(async input =&gt; SyncPreparingResponseAction.Succeeded)\n    .SetupGetSourceBatchItems(async input =&gt; /* fetch batch */)\n    .SetupMapping(async (items, actionType) =&gt; /* transform */)\n    .SetupStoreBatchData(async input =&gt; /* write to destination */)\n    .SetupBatchCompleted(async input =&gt; true);\n\nvar success = await engine.RunAsync();\n</code></pre>"},{"location":"integrations/sync-agent/architecture.html#data-adapter-model","title":"Data Adapter Model","text":"<p>Rather than wiring up every stage manually, the Sync Agent provides Data Adapters \u2014 pre-built components that encapsulate the logic for common data systems.</p> <p>A Data Adapter implements the <code>ISyncDataAdapter</code> interface and automatically configures the relevant stages of the Sync Engine when its <code>Configure</code> method is called.</p> <p>This means a typical pipeline setup is as simple as:</p> <ol> <li>Create a <code>SyncEngine</code>.</li> <li>Attach a source adapter (e.g., CSV, EF Core).</li> <li>Attach a destination adapter (e.g., Cosmos DB, EF Core, DuckDB).</li> <li>Provide a mapping function.</li> <li>Call <code>RunAsync()</code>.</li> </ol> <p>See Data Adapters for details on each built-in adapter and Getting Started for end-to-end examples.</p>"},{"location":"integrations/sync-agent/configuration.html","title":"Configuration Reference","text":"<p>This page provides a comprehensive reference for all configuration types available in the ADP Sync Agent.</p>"},{"location":"integrations/sync-agent/configuration.html#sync-engine-configuration","title":"Sync Engine Configuration","text":"<p>The Sync Engine is configured via the <code>Configure</code> method on <code>ISyncEngine&lt;TSource, TDestination&gt;</code>.</p>"},{"location":"integrations/sync-agent/configuration.html#parameters","title":"Parameters","text":"Parameter Type Default Description <code>batchSize</code> <code>long?</code> <code>null</code> Number of items per batch. If <code>null</code>, all items are processed in a single batch (when total count is known). <code>maxRetryCount</code> <code>long</code> <code>0</code> Maximum number of retries per batch before applying the default retry action. <code>operationTimeoutInSeconds</code> <code>long</code> <code>300</code> Total time allowed for the pipeline run. A <code>CancellationToken</code> is created with this timeout. <code>defaultRetryAction</code> <code>RetryAction</code> <code>RetryAndStopAfterLastRetry</code> Default behavior when a batch fails and no custom <code>BatchRetry</code> handler is configured. <code>actionExecutionAndOrder</code> <code>IEnumerable&lt;SyncActionType&gt;</code> <code>[Delete, Update, Add]</code> Which actions to run and in what order."},{"location":"integrations/sync-agent/configuration.html#example","title":"Example","text":"<pre><code>engine.Configure(\n    batchSize: 1000,\n    maxRetryCount: 3,\n    operationTimeoutInSeconds: 600,\n    defaultRetryAction: RetryAction.RetryAndContinueAfterLastRetry);\n</code></pre>"},{"location":"integrations/sync-agent/configuration.html#custom-action-order","title":"Custom Action Order","text":"<pre><code>engine.Configure(\n    actionExecutionAndOrder: [SyncActionType.Add, SyncActionType.Update],\n    batchSize: 500,\n    maxRetryCount: 2);\n</code></pre>"},{"location":"integrations/sync-agent/configuration.html#enums","title":"Enums","text":""},{"location":"integrations/sync-agent/configuration.html#syncactiontype","title":"SyncActionType","text":"<p>Defines the type of data operation being performed.</p> Value Description <code>Add</code> Insert new records into the destination. <code>Update</code> Update existing records in the destination. <code>Delete</code> Remove records from the destination. <code>Upsert</code> Insert or update \u2014 used by adapters that don't distinguish between add and update (e.g., Cosmos DB)."},{"location":"integrations/sync-agent/configuration.html#retryaction","title":"RetryAction","text":"<p>Controls what happens when a batch fails.</p> Value Description <code>RetryAndStopAfterLastRetry</code> Retry up to <code>MaxRetryCount</code>, then stop the entire action. <code>BatchCompleted</code> is not called. (Default) <code>RetryAndContinueAfterLastRetry</code> Retry up to <code>MaxRetryCount</code>, then skip the failed batch and continue to the next. <code>BatchCompleted</code> is called. <code>Skip</code> Skip the failed batch immediately and continue to the next batch. <code>Stop</code> Stop the entire action immediately. <code>BatchCompleted</code> is not called."},{"location":"integrations/sync-agent/configuration.html#syncpreparingresponseaction","title":"SyncPreparingResponseAction","text":"<p>Returned by the <code>Preparing</code> stage to control pipeline flow.</p> Value Description <code>Succeeded</code> Preparation was successful \u2014 continue to the action loop. <code>Failed</code> Preparation failed \u2014 mark the pipeline as failed. <code>Skipped</code> Nothing to process \u2014 mark the pipeline as successful without running any actions."},{"location":"integrations/sync-agent/configuration.html#syncstoredataresulttype","title":"SyncStoreDataResultType","text":"<p>Describes the outcome of a <code>StoreBatchData</code> operation.</p> Value Description <code>Succeeded</code> All items were written successfully. <code>Failed</code> All items failed to write. <code>Partial</code> Some items succeeded and some failed. <code>Skipped</code> All items were skipped (none succeeded or failed)."},{"location":"integrations/sync-agent/configuration.html#syncoperationtype","title":"SyncOperationType","text":"<p>Identifies which lifecycle stage is currently executing. Used primarily by the logging system.</p> Value <code>Preparing</code> <code>ActionStarted</code> <code>SourceTotalItemCount</code> <code>BatchStarted</code> <code>GetSourceBatchItems</code> <code>Mapping</code> <code>StoreBatchData</code> <code>BatchRetry</code> <code>BatchCompleted</code> <code>ActionCompleted</code> <code>Failed</code> <code>Succeeded</code> <code>Finished</code>"},{"location":"integrations/sync-agent/configuration.html#pipeline-stage-input-types","title":"Pipeline Stage Input Types","text":"<p>Each stage in the Sync Engine receives a <code>SyncFunctionInput&lt;T&gt;</code> that provides context about the current operation.</p>"},{"location":"integrations/sync-agent/configuration.html#syncfunctioninput","title":"SyncFunctionInput","text":"<p>The base input for all stages.</p> Property Type Description <code>CancellationToken</code> <code>CancellationToken</code> Token that is cancelled when the operation timeout expires. <code>SyncProgressIndicators</code> <code>IEnumerable&lt;ISyncEngineLogger&gt;</code> Registered loggers for progress tracking and logging."},{"location":"integrations/sync-agent/configuration.html#syncfunctioninputt","title":"SyncFunctionInput&lt;T&gt;","text":"<p>Extends <code>SyncFunctionInput</code> with stage-specific data via the <code>Input</code> property.</p>"},{"location":"integrations/sync-agent/configuration.html#syncactionstatus","title":"SyncActionStatus","text":"<p>Provides batch progress information. Available in most batch-level stages.</p> Property Type Description <code>CurrentStep</code> <code>long</code> Zero-based index of the current batch. <code>TotalSteps</code> <code>long?</code> Total number of batches (if known). <code>BatchSize</code> <code>long</code> Configured batch size. <code>TotalCount</code> <code>long?</code> Total item count (if known). <code>CurrentRetryCount</code> <code>long</code> Number of retries so far for this batch. <code>MaxRetryCount</code> <code>long</code> Maximum retries allowed. <code>ActionType</code> <code>SyncActionType</code> The current action type (Add, Update, Delete, Upsert)."},{"location":"integrations/sync-agent/configuration.html#syncgetbatchdatainputt","title":"SyncGetBatchDataInput&lt;T&gt;","text":"<p>Input for <code>GetSourceBatchItems</code>.</p> Property Type Description <code>PreviousItems</code> <code>IEnumerable&lt;T?&gt;?</code> On retry, contains the previous batch items. <code>null</code> on first attempt. <code>Status</code> <code>SyncActionStatus</code> Current batch progress."},{"location":"integrations/sync-agent/configuration.html#syncmappinginputtsource-tdestination","title":"SyncMappingInput&lt;TSource, TDestination&gt;","text":"<p>Input for the <code>Mapping</code> stage.</p> Property Type Description <code>SourceItems</code> <code>IEnumerable&lt;TSource?&gt;?</code> The current batch of source items. <code>PreviousMappedItem</code> <code>IEnumerable&lt;TDestination?&gt;?</code> On retry, the previously mapped items. <code>null</code> on first attempt. <code>Status</code> <code>SyncActionStatus</code> Current batch progress."},{"location":"integrations/sync-agent/configuration.html#syncstoredatainputt","title":"SyncStoreDataInput&lt;T&gt;","text":"<p>Input for <code>StoreBatchData</code>.</p> Property Type Description <code>Items</code> <code>IEnumerable&lt;T?&gt;?</code> The mapped items to write to the destination. <code>PreviousResult</code> <code>SyncStoreDataResult&lt;T&gt;?</code> On retry, the result from the previous attempt. <code>null</code> on first attempt. <code>Status</code> <code>SyncActionStatus</code> Current batch progress."},{"location":"integrations/sync-agent/configuration.html#syncstoredataresultt","title":"SyncStoreDataResult&lt;T&gt;","text":"<p>Returned by <code>StoreBatchData</code>.</p> Property Type Description <code>SucceededItems</code> <code>IEnumerable&lt;T?&gt;?</code> Items that were written successfully. <code>FailedItems</code> <code>IEnumerable&lt;T?&gt;?</code> Items that failed. <code>SkippedItems</code> <code>IEnumerable&lt;T?&gt;?</code> Items that were skipped. <code>RetryException</code> <code>RetryException?</code> Set to trigger a retry. <code>null</code> to skip retry. <code>ResultType</code> <code>SyncStoreDataResultType</code> Computed from the items \u2014 <code>Succeeded</code>, <code>Failed</code>, <code>Partial</code>, or <code>Skipped</code>."},{"location":"integrations/sync-agent/configuration.html#syncbatchcompleteretryinputtsource-tdestination","title":"SyncBatchCompleteRetryInput&lt;TSource, TDestination&gt;","text":"<p>Input for <code>BatchCompleted</code> and <code>BatchRetry</code>.</p> Property Type Description <code>SourceItems</code> <code>IEnumerable&lt;TSource?&gt;?</code> The source items from this batch. <code>StoreDataResult</code> <code>SyncStoreDataResult&lt;TDestination&gt;?</code> The storage result (succeeded/failed/skipped items). <code>Status</code> <code>SyncActionStatus</code> Current batch progress. <code>Exception</code> <code>Exception?</code> The exception that caused the failure (for <code>BatchRetry</code>). <code>null</code> for <code>BatchCompleted</code>."},{"location":"integrations/sync-agent/configuration.html#syncactioncompletedinput","title":"SyncActionCompletedInput","text":"<p>Input for <code>ActionCompleted</code>.</p> Property Type Description <code>ActionType</code> <code>SyncActionType</code> The action type that just completed. <code>Succeeded</code> <code>bool</code> Whether all batches in this action completed successfully."},{"location":"integrations/sync-agent/configuration.html#adapter-specific-configurations","title":"Adapter-Specific Configurations","text":"<p>Refer to the Data Adapters page for configuration details specific to each built-in adapter:</p> <ul> <li>CSV Source Configuration</li> <li>EF Core Source Configuration</li> <li>Cosmos DB Destination Configuration</li> <li>EF Core Destination Configuration</li> <li>DuckDB Destination Configuration</li> </ul>"},{"location":"integrations/sync-agent/data-adapters.html","title":"Data Adapters","text":"<p>Data Adapters are the building blocks of every ADP Sync Agent pipeline. They encapsulate the logic for reading from a data source or writing to a data destination, and they automatically wire themselves into the Sync Engine lifecycle.</p> <p>The Sync Agent ships with built-in adapters for the most common enterprise data systems. When a built-in adapter doesn't fit, you can implement the <code>ISyncDataAdapter</code> interface to create your own.</p>"},{"location":"integrations/sync-agent/data-adapters.html#source-adapters","title":"Source Adapters","text":"<p>Source adapters are responsible for reading data from the origin system and feeding it to the Sync Engine in batches.</p>"},{"location":"integrations/sync-agent/data-adapters.html#csv-source-adapters","title":"CSV Source Adapters","text":"<p>The CSV source adapters are designed for file-based data integration \u2014 a common scenario when dealer management systems export data as flat files.</p> <p>Rather than naively re-processing the entire file on every run, the CSV adapters use a git-based diff strategy:</p> <ol> <li>Load the previously synced version of the CSV file from a content repository.</li> <li>Load the new version from the source location.</li> <li>Compare the two versions using a git diff to identify only the added and deleted lines.</li> <li>Feed only the changes into the pipeline as Add and Delete actions.</li> </ol> <p>This approach dramatically reduces processing volume and ensures that only actual changes are synced.</p> <p>Reordered Lines</p> <p>CSV files from external systems may contain the same data in a different order between exports. The <code>SkipReorderedLines</code> option detects lines that appear in both the added and deleted sets (i.e., they moved but didn't change) and excludes them from processing.</p> <p>The Sync Agent provides two CSV adapter implementations:</p>"},{"location":"integrations/sync-agent/data-adapters.html#csvhelpercsvsyncdatasource","title":"CsvHelperCsvSyncDataSource","text":"<p>Uses the CsvHelper library for CSV parsing. This is the recommended adapter for most scenarios \u2014 it supports header-based mapping, flexible configuration, and culture-aware parsing.</p> <pre><code>// Register in DI\nservices.AddCSVSyncDataSource&lt;FileSystemStorageService&gt;(options =&gt;\n{\n    options.CompareWorkingDirectory = @\"C:\\temp\\csv-compare\";\n    options.SourceBasePath = @\"C:\\data\\incoming\";\n    options.DestinationBasePath = @\"C:\\data\\synced\";\n});\n</code></pre>"},{"location":"integrations/sync-agent/data-adapters.html#filehelpercsvsyncdatasource","title":"FileHelperCsvSyncDataSource","text":"<p>Uses the FileHelpers library for CSV parsing. This adapter requires your CSV model class to inherit from <code>CacheableCSV</code>, which provides an auto-computed <code>id</code> field (SHA512 hash of the raw CSV line).</p> <pre><code>public class PartRecord : CacheableCSV\n{\n    public string PartNumber { get; set; }\n    public string Description { get; set; }\n    public decimal Price { get; set; }\n}\n</code></pre>"},{"location":"integrations/sync-agent/data-adapters.html#csv-source-configuration","title":"CSV Source Configuration","text":"<p>Both CSV adapters are configured with <code>CSVSyncDataSourceConfigurations&lt;T&gt;</code>:</p> Property Type Description <code>CSVFileName</code> <code>string</code> Required. Name of the CSV file to sync. <code>SourceContainerOrShareName</code> <code>string?</code> Container or file share name for the source (Azure Storage). <code>SourceDirectory</code> <code>string?</code> Directory path within the source container. <code>DestinationContainerOrShareName</code> <code>string?</code> Container or file share name for the synced copy. <code>DestinationDirectory</code> <code>string?</code> Directory path within the destination container. <code>SkipReorderedLines</code> <code>bool</code> When <code>true</code>, lines that appear in both added and deleted sets are excluded. <code>HasHeaderRecord</code> <code>bool</code> Whether the CSV file has a header row. Default: <code>true</code>. <code>ProccessSourceData</code> <code>Func&lt;...&gt;?</code> Optional function to pre-process source data before comparison. <code>ProccessAddedItems</code> <code>Func&lt;...&gt;?</code> Optional function to post-process added items after diffing. <code>ProccessDeletedItems</code> <code>Func&lt;...&gt;?</code> Optional function to post-process deleted items after diffing."},{"location":"integrations/sync-agent/data-adapters.html#storage-backends","title":"Storage Backends","text":"<p>The CSV adapters rely on an <code>IStorageService</code> to load and store CSV files. The built-in <code>FileSystemStorageService</code> works with local or network file paths. For Azure Blob Storage or Azure File Share, implement a custom <code>IStorageService</code>.</p>"},{"location":"integrations/sync-agent/data-adapters.html#ef-core-source-adapter","title":"EF Core Source Adapter","text":"<p>The <code>EFCoreSyncDataSource</code> reads data from a SQL Server database (or any EF Core-compatible provider) and feeds it to the pipeline in batches.</p> <p>Key features:</p> <ul> <li>Automatic batching by primary key with ordered, keyset-based pagination.</li> <li>Sync timestamp tracking \u2014 after a successful batch, updates a <code>LastSynced</code> or equivalent timestamp column on processed records to avoid re-syncing.</li> <li>Custom queries \u2014 filter and project data using LINQ before it enters the pipeline.</li> </ul> <pre><code>var source = engine.SetDataAddapter&lt;EFCoreSyncDataSource&lt;PartEntity, AppDbContext&gt;&gt;(services);\n\nsource.Configure(new EFCoreSyncDataSourceConfigurations&lt;PartEntity&gt;\n{\n    Query = (query, actionType) =&gt; query.Where(p =&gt; p.LastModified &gt; lastSync),\n    EntityKey = p =&gt; p.Id,\n    SyncTimestamp = p =&gt; p.LastSyncedAt,\n});\n</code></pre>"},{"location":"integrations/sync-agent/data-adapters.html#ef-core-source-configuration","title":"EF Core Source Configuration","text":"<p><code>EFCoreSyncDataSourceConfigurations&lt;TEntity, TSource, TDestination&gt;</code>:</p> Property Type Description <code>Query</code> <code>Func&lt;IQueryable&lt;TEntity&gt;, SyncActionType, IQueryable&lt;TSource&gt;&gt;</code> Required. LINQ query to filter and project source data. Receives the action type for conditional filtering. <code>EntityKey</code> <code>Expression&lt;Func&lt;TEntity, object&gt;&gt;?</code> Primary key expression used for keyset-based batching. <code>SourceKey</code> <code>Expression&lt;Func&lt;TSource, object&gt;&gt;?</code> Key expression on the source projection type. <code>DestinationKey</code> <code>Expression&lt;Func&lt;TDestination, object&gt;&gt;?</code> Key expression on the destination type \u2014 used to match items when updating sync timestamps. <code>SyncTimestamp</code> <code>Expression&lt;Func&lt;TEntity, DateTimeOffset?&gt;&gt;?</code> Property to update with the sync timestamp after each successful batch. <code>UpdateSyncTimeStampForSkippedItems</code> <code>bool</code> If <code>true</code>, also updates the sync timestamp for items that were skipped during storage. Default: <code>false</code>. <code>UpdateTimeStampFilter</code> <code>Func&lt;...&gt;?</code> Custom filter for selecting which entity records to update with the sync timestamp."},{"location":"integrations/sync-agent/data-adapters.html#generic-overloads","title":"Generic Overloads","text":"<p>The EF Core source adapter comes in three generic overloads to handle different scenarios:</p> Overload Use Case <code>EFCoreSyncDataSource&lt;T, TDbContext&gt;</code> Entity, source, and destination are the same type. <code>EFCoreSyncDataSource&lt;TSource, TDestination, TDbContext&gt;</code> Entity and source are the same; destination differs. <code>EFCoreSyncDataSource&lt;TEntity, TSource, TDestination, TDbContext&gt;</code> All three types are different (e.g., entity \u2192 DTO \u2192 Cosmos document)."},{"location":"integrations/sync-agent/data-adapters.html#destination-adapters","title":"Destination Adapters","text":"<p>Destination adapters are responsible for writing transformed data to the target system.</p>"},{"location":"integrations/sync-agent/data-adapters.html#cosmos-db-destination-adapter","title":"Cosmos DB Destination Adapter","text":"<p>The <code>CosmosSyncDataDestination</code> writes data to Azure Cosmos DB containers. It treats Add and Update actions as upsert operations and supports Delete actions natively.</p> <p>Key features:</p> <ul> <li>Parallel upserts with concurrency control.</li> <li>Built-in Polly retry pipeline for transient Cosmos DB failures.</li> <li>Partition key support \u2014 up to 3 levels of hierarchical partition keys via expressions.</li> <li>Patch operations \u2014 optionally use Cosmos DB partial updates instead of full document replacement.</li> <li>Custom Cosmos actions \u2014 override the default upsert/delete behavior per item (e.g., change a delete to an upsert with a soft-delete flag).</li> </ul> <pre><code>var destination = engine.SetDataAddapter&lt;CosmosSyncDataDestination&lt;PartDoc, CosmosClient&gt;&gt;(services);\n\ndestination.Configure(new CosmosSyncDataDestinationConfigurations&lt;PartDoc&gt;\n{\n    DatabaseId = \"PartsDB\",\n    ContainerId = \"Parts\",\n    PartitionKeyLevel1Expression = x =&gt; x.Region,\n});\n</code></pre>"},{"location":"integrations/sync-agent/data-adapters.html#cosmos-db-destination-configuration","title":"Cosmos DB Destination Configuration","text":"<p><code>CosmosSyncDataDestinationConfigurations&lt;TDestination, TCosmos&gt;</code>:</p> Property Type Description <code>DatabaseId</code> <code>string</code> Required. Cosmos DB database ID. <code>ContainerId</code> <code>string</code> Required. Cosmos DB container ID. <code>PartitionKeyLevel1Expression</code> <code>Expression&lt;...&gt;</code> Required. Expression for the first level of the partition key. <code>PartitionKeyLevel2Expression</code> <code>Expression&lt;...&gt;?</code> Second level of a hierarchical partition key. <code>PartitionKeyLevel3Expression</code> <code>Expression&lt;...&gt;?</code> Third level of a hierarchical partition key. <code>CosmosAction</code> <code>Func&lt;...&gt;?</code> Custom function to override the default action (upsert/delete) per item. <code>UsePatch</code> <code>bool</code> Use Cosmos DB patch (partial update) instead of full document replace. <code>PropertiesToPatch</code> <code>Expression&lt;...&gt;[]?</code> Specific properties to patch. If empty and <code>UsePatch</code> is <code>true</code>, all properties are patched."},{"location":"integrations/sync-agent/data-adapters.html#ef-core-destination-adapter","title":"EF Core Destination Adapter","text":"<p>The <code>EFCoreSyncDataDestination</code> writes data to a SQL Server database (or any EF Core-compatible provider) using bulk operations powered by EFCore.BulkExtensions.</p> <p>Key features:</p> <ul> <li>Bulk insert or update \u2014 uses <code>BulkInsertOrUpdateAsync</code> for high-performance writes.</li> <li>Configurable BulkConfig \u2014 full access to the underlying BulkExtensions configuration.</li> </ul> <pre><code>var destination = engine.SetDataAddapter&lt;EFCoreSyncDataDestination&lt;PartEntity, AppDbContext&gt;&gt;(services);\n\ndestination.Configure(new EFCoreSyncDataDestinationConfigurations\n{\n    BulkConfig = new BulkConfig { SetOutputIdentity = true }\n});\n</code></pre>"},{"location":"integrations/sync-agent/data-adapters.html#ef-core-destination-configuration","title":"EF Core Destination Configuration","text":"<p><code>EFCoreSyncDataDestinationConfigurations</code>:</p> Property Type Description <code>BulkConfig</code> <code>BulkConfig</code> Configuration for EFCore.BulkExtensions (batch size, identity handling, etc.)."},{"location":"integrations/sync-agent/data-adapters.html#duckdb-destination-adapter","title":"DuckDB Destination Adapter","text":"<p>The <code>DuckDBSyncDataDestination</code> writes data to a DuckDB database \u2014 an in-process analytical database that's ideal for reporting, analytics, and data warehousing scenarios.</p> <p>Key features:</p> <ul> <li>Automatic table creation from the destination model's properties with correct DuckDB type mapping.</li> <li>Staging table pattern \u2014 data is first bulk-loaded into a temporary staging table, then upserted into the main table for atomicity.</li> <li>Primary key support \u2014 configurable primary key for upsert behavior.</li> <li>Complex type handling \u2014 nested objects are stored as JSON columns.</li> </ul> <pre><code>var destination = engine.SetDataAddapter&lt;DuckDBSyncDataDestination&lt;SourceModel, DestModel, DuckDBConnection&gt;&gt;(services);\n\ndestination.Configure(new DuckDBSyncDataDestinationConfigurations&lt;SourceModel, DestModel&gt;\n{\n    TableName = \"Parts\",\n    PrimaryKey = x =&gt; x.PartNumber,\n    ContinueAfterFail = true,\n});\n</code></pre>"},{"location":"integrations/sync-agent/data-adapters.html#duckdb-destination-configuration","title":"DuckDB Destination Configuration","text":"<p><code>DuckDBSyncDataDestinationConfigurations&lt;TSource, TDestination&gt;</code>:</p> Property Type Description <code>TableName</code> <code>string</code> Required. Name of the DuckDB table. <code>PrimaryKey</code> <code>Expression&lt;...&gt;?</code> Expression for the primary key column (enables upsert). <code>ContinueAfterFail</code> <code>bool</code> If <code>true</code>, continue processing remaining items after a row fails. Default: <code>false</code>."},{"location":"integrations/sync-agent/data-adapters.html#duckdb-type-mapping","title":"DuckDB Type Mapping","text":"<p>The adapter automatically maps C# types to DuckDB column types:</p> C# Type DuckDB Type <code>bool</code> <code>BOOLEAN</code> <code>int</code> <code>INTEGER</code> <code>long</code> <code>BIGINT</code> <code>double</code> <code>DOUBLE</code> <code>decimal</code> <code>DECIMAL(38, 10)</code> <code>string</code> <code>VARCHAR</code> <code>DateTime</code> <code>TIMESTAMP</code> <code>DateTimeOffset</code> <code>TIMESTAMPTZ</code> <code>Guid</code> <code>UUID</code> <code>enum</code> <code>INTEGER</code> Complex types <code>JSON</code>"},{"location":"integrations/sync-agent/data-adapters.html#custom-adapters","title":"Custom Adapters","text":"<p>When the built-in adapters don't cover your use case, you can implement the <code>ISyncDataAdapter</code> interface to create a custom adapter for any data system.</p> <p>A custom adapter must implement:</p> <ul> <li><code>SetSyncService</code> \u2014 Store a reference to the Sync Engine.</li> <li><code>Configure</code> \u2014 Wire up the adapter's logic into the engine's lifecycle stages.</li> <li>The relevant lifecycle methods (<code>Preparing</code>, <code>GetSourceBatchItems</code>, <code>StoreBatchData</code>, etc.).</li> </ul> <p>Methods that are not relevant to your adapter can throw <code>NotImplementedException</code> \u2014 only the methods you wire into the engine via <code>Configure</code> will be called.</p> <pre><code>public class MyCustomSource&lt;TSource, TDestination&gt; \n    : ISyncDataAdapter&lt;TSource, TDestination, MyConfig, MyCustomSource&lt;TSource, TDestination&gt;&gt;\n    where TSource : class\n    where TDestination : class\n{\n    public ISyncEngine&lt;TSource, TDestination&gt; SyncService { get; private set; }\n    public MyConfig? Configurations { get; private set; }\n\n    public MyCustomSource&lt;TSource, TDestination&gt; SetSyncService(ISyncEngine&lt;TSource, TDestination&gt; syncService)\n    {\n        SyncService = syncService;\n        return this;\n    }\n\n    public ISyncEngine&lt;TSource, TDestination&gt; Configure(MyConfig configurations, bool configureSyncService = true)\n    {\n        Configurations = configurations;\n\n        if (configureSyncService)\n            SyncService\n                .SetupGetSourceBatchItems(GetSourceBatchItems)\n                .SetupSourceTotalItemCount(SourceTotalItemCount);\n\n        return SyncService;\n    }\n\n    // Implement the methods you need...\n}\n</code></pre> <p>See Architecture for details on each lifecycle stage and when it's called.</p>"},{"location":"integrations/sync-agent/getting-started.html","title":"Getting Started","text":"<p>This guide walks you through setting up the ADP Sync Agent with dependency injection and building your first data synchronization pipeline.</p>"},{"location":"integrations/sync-agent/getting-started.html#installation","title":"Installation","text":"<p>Install the NuGet package:</p> <pre><code>dotnet add package ShiftSoftware.ADP.SyncAgent\n</code></pre>"},{"location":"integrations/sync-agent/getting-started.html#service-registration","title":"Service Registration","text":"<p>The Sync Agent provides extension methods on <code>IServiceCollection</code> to register its components:</p> <pre><code>services.AddSyncService();                  // Registers SyncEngine&lt;T&gt; and SyncEngine&lt;TSource, TDestination&gt;\nservices.AddEFCoreSyncDataSource();         // Registers EFCoreSyncDataSource adapters\nservices.AddEFCoreSyncDataDestination();    // Registers EFCoreSyncDataDestination adapters\nservices.AddCosmosSyncDataDestination();    // Registers CosmosSyncDataDestination adapters\n\n// For CSV-based pipelines\nservices.AddCSVSyncDataSource&lt;FileSystemStorageService&gt;(options =&gt;\n{\n    options.CompareWorkingDirectory = @\"C:\\temp\\csv-compare\";\n    options.SourceBasePath = @\"C:\\data\\incoming\";\n    options.DestinationBasePath = @\"C:\\data\\synced\";\n});\n</code></pre>"},{"location":"integrations/sync-agent/getting-started.html#example-1-ef-core-to-cosmos-db","title":"Example 1: EF Core to Cosmos DB","text":"<p>A common scenario \u2014 reading from a SQL Server database and syncing to Azure Cosmos DB.</p> <pre><code>public class PartSyncJob\n{\n    private readonly IServiceProvider _services;\n    private readonly ILogger&lt;PartSyncJob&gt; _logger;\n\n    public PartSyncJob(IServiceProvider services, ILogger&lt;PartSyncJob&gt; logger)\n    {\n        _services = services;\n        _logger = logger;\n    }\n\n    public async Task&lt;bool&gt; RunAsync()\n    {\n        // 1. Create a Sync Engine\n        await using var engine = new SyncEngine&lt;PartEntity, PartCosmosDoc&gt;(_services);\n\n        // 2. Configure the engine\n        engine.Configure(\n            batchSize: 500,\n            maxRetryCount: 3,\n            operationTimeoutInSeconds: 600);\n\n        // 3. Register a logger\n        engine.RegisterLogger(new SyncEngineILogger(_logger));\n\n        // 4. Attach the EF Core source adapter\n        var source = engine\n            .SetDataAddapter&lt;EFCoreSyncDataSource&lt;PartEntity, AppDbContext&gt;&gt;(_services);\n\n        source.Configure(new EFCoreSyncDataSourceConfigurations&lt;PartEntity&gt;\n        {\n            Query = (query, actionType) =&gt; query\n                .Where(p =&gt; p.LastSyncedAt == null || p.LastModified &gt; p.LastSyncedAt),\n            EntityKey = p =&gt; p.Id,\n            SyncTimestamp = p =&gt; p.LastSyncedAt,\n        });\n\n        // 5. Attach the Cosmos DB destination adapter\n        var destination = engine\n            .SetDataAddapter&lt;CosmosSyncDataDestination&lt;PartEntity, PartCosmosDoc, CosmosClient&gt;&gt;(_services);\n\n        destination.Configure(new CosmosSyncDataDestinationConfigurations&lt;PartEntity, PartCosmosDoc&gt;\n        {\n            DatabaseId = \"PartsDB\",\n            ContainerId = \"Parts\",\n            PartitionKeyLevel1Expression = x =&gt; x.Region,\n        });\n\n        // 6. Set up mapping\n        engine.SetupMapping(async (items, actionType) =&gt;\n        {\n            return items?.Select(p =&gt; p is null ? null : new PartCosmosDoc\n            {\n                id = p.Id.ToString(),\n                PartNumber = p.PartNumber,\n                Description = p.Description,\n                Price = p.Price,\n                Region = p.Region,\n            });\n        });\n\n        // 7. Run the pipeline\n        return await engine.RunAsync();\n    }\n}\n</code></pre>"},{"location":"integrations/sync-agent/getting-started.html#example-2-csv-to-cosmos-db","title":"Example 2: CSV to Cosmos DB","text":"<p>Syncing data from CSV flat files to Azure Cosmos DB \u2014 common when integrating with dealer management systems that export data as files.</p> <pre><code>public class PriceSyncJob\n{\n    private readonly IServiceProvider _services;\n    private readonly ILogger&lt;PriceSyncJob&gt; _logger;\n\n    public PriceSyncJob(IServiceProvider services, ILogger&lt;PriceSyncJob&gt; logger)\n    {\n        _services = services;\n        _logger = logger;\n    }\n\n    public async Task&lt;bool&gt; RunAsync()\n    {\n        await using var engine = new SyncEngine&lt;PriceRecord, PriceCosmosDoc&gt;(_services);\n\n        engine.Configure(\n            actionExecutionAndOrder: [SyncActionType.Delete, SyncActionType.Add],\n            batchSize: 1000,\n            maxRetryCount: 2,\n            operationTimeoutInSeconds: 900);\n\n        engine.RegisterLogger(new SyncEngineILogger(_logger));\n\n        // Attach CSV source (CsvHelper-based)\n        var source = engine\n            .SetDataAddapter&lt;CsvHelperCsvSyncDataSource&lt;PriceRecord, PriceCosmosDoc&gt;&gt;(_services);\n\n        source.Configure(new CSVSyncDataSourceConfigurations&lt;PriceRecord&gt;\n        {\n            CSVFileName = \"prices.csv\",\n            SourceDirectory = \"dealer-exports\",\n            DestinationDirectory = \"synced\",\n            SkipReorderedLines = true,\n            HasHeaderRecord = true,\n        });\n\n        // Attach Cosmos DB destination\n        var destination = engine\n            .SetDataAddapter&lt;CosmosSyncDataDestination&lt;PriceRecord, PriceCosmosDoc, CosmosClient&gt;&gt;(_services);\n\n        destination.Configure(new CosmosSyncDataDestinationConfigurations&lt;PriceRecord, PriceCosmosDoc&gt;\n        {\n            DatabaseId = \"PricingDB\",\n            ContainerId = \"Prices\",\n            PartitionKeyLevel1Expression = x =&gt; x.Region,\n        });\n\n        // Mapping\n        engine.SetupMapping(async (items, actionType) =&gt;\n        {\n            return items?.Select(p =&gt; p is null ? null : new PriceCosmosDoc\n            {\n                id = p.PartNumber,\n                PartNumber = p.PartNumber,\n                Price = p.Price,\n                Currency = p.Currency,\n                Region = p.Region,\n            });\n        });\n\n        return await engine.RunAsync();\n    }\n}\n</code></pre>"},{"location":"integrations/sync-agent/getting-started.html#example-3-ef-core-to-ef-core-database-to-database","title":"Example 3: EF Core to EF Core (Database to Database)","text":"<p>Syncing data between two SQL Server databases \u2014 useful for replicating data across environments or aggregating dealer data.</p> <pre><code>public class OrderSyncJob\n{\n    private readonly IServiceProvider _services;\n\n    public OrderSyncJob(IServiceProvider services) =&gt; _services = services;\n\n    public async Task&lt;bool&gt; RunAsync()\n    {\n        await using var engine = new SyncEngine&lt;OrderEntity&gt;(_services);\n\n        engine.Configure(batchSize: 200, maxRetryCount: 1);\n\n        // Source: read from DealerDbContext\n        var source = engine\n            .SetDataAddapter&lt;EFCoreSyncDataSource&lt;OrderEntity, DealerDbContext&gt;&gt;(_services);\n\n        source.Configure(new EFCoreSyncDataSourceConfigurations&lt;OrderEntity&gt;\n        {\n            Query = (query, actionType) =&gt; query.Where(o =&gt; o.Status == \"Completed\"),\n            EntityKey = o =&gt; o.OrderId,\n        });\n\n        // Destination: write to CentralDbContext\n        var destination = engine\n            .SetDataAddapter&lt;EFCoreSyncDataDestination&lt;OrderEntity, CentralDbContext&gt;&gt;(_services);\n\n        destination.Configure(new EFCoreSyncDataDestinationConfigurations());\n\n        // Same type \u2014 use identity mapping\n        engine.SetupMapping(async (items, actionType) =&gt; items);\n\n        return await engine.RunAsync();\n    }\n}\n</code></pre>"},{"location":"integrations/sync-agent/getting-started.html#example-4-ef-core-to-duckdb","title":"Example 4: EF Core to DuckDB","text":"<p>Syncing operational data into DuckDB for analytics and reporting.</p> <pre><code>public class AnalyticsSyncJob\n{\n    private readonly IServiceProvider _services;\n\n    public AnalyticsSyncJob(IServiceProvider services) =&gt; _services = services;\n\n    public async Task&lt;bool&gt; RunAsync()\n    {\n        await using var engine = new SyncEngine&lt;SalesEntity, SalesAnalyticsRow&gt;(_services);\n\n        engine.Configure(batchSize: 5000);\n\n        var source = engine\n            .SetDataAddapter&lt;EFCoreSyncDataSource&lt;SalesEntity, SalesAnalyticsRow, SalesDbContext&gt;&gt;(_services);\n\n        source.Configure(new EFCoreSyncDataSourceConfigurations&lt;SalesEntity, SalesAnalyticsRow&gt;\n        {\n            Query = (query, actionType) =&gt; query\n                .Select(s =&gt; new SalesAnalyticsRow\n                {\n                    SaleId = s.Id,\n                    DealerId = s.DealerId,\n                    Amount = s.TotalAmount,\n                    SaleDate = s.CreatedAt,\n                }),\n            EntityKey = s =&gt; s.Id,\n        });\n\n        var destination = engine\n            .SetDataAddapter&lt;DuckDBSyncDataDestination&lt;SalesEntity, SalesAnalyticsRow, DuckDBConnection&gt;&gt;(_services);\n\n        destination.Configure(new DuckDBSyncDataDestinationConfigurations&lt;SalesEntity, SalesAnalyticsRow&gt;\n        {\n            TableName = \"Sales\",\n            PrimaryKey = x =&gt; x.SaleId,\n        });\n\n        engine.SetupMapping(async (items, actionType) =&gt; items);\n\n        return await engine.RunAsync();\n    }\n}\n</code></pre>"},{"location":"integrations/sync-agent/getting-started.html#example-5-using-automapper","title":"Example 5: Using AutoMapper","text":"<p>The Sync Agent integrates with AutoMapper via the <code>UseAutoMapper</code> extension method:</p> <pre><code>engine.UseAutoMapper(mapper);\n</code></pre> <p>This replaces the need for a manual <code>SetupMapping</code> call. The mapper will be used to transform <code>TSource</code> items into <code>TDestination</code> items automatically.</p>"},{"location":"integrations/sync-agent/getting-started.html#pipeline-triggers","title":"Pipeline Triggers","text":"<p>The Sync Agent does not dictate how pipelines are triggered. You can integrate it with any scheduling or event system:</p> Trigger Example Scheduled Jobs Hangfire, Azure Functions (Timer Trigger), Windows Services, cron jobs. Event-Based Azure Service Bus messages, Azure Blob Storage events, database change feeds. On-Demand API endpoints, manual UI triggers."},{"location":"integrations/sync-agent/getting-started.html#tips","title":"Tips","text":"<p>Source Before Destination</p> <p>Always configure the source adapter before the destination adapter. The adapters chain their lifecycle hooks \u2014 the destination adapter may depend on hooks already set by the source.</p> <p>Batch Size Tuning</p> <p>Start with a moderate batch size (500\u20131000) and adjust based on your data volume and destination latency. Smaller batches give more granular retry but add overhead. Larger batches are more efficient but risk more data on failure.</p> <p>Timeout Planning</p> <p>Set <code>operationTimeoutInSeconds</code> generously for initial syncs or large datasets. For recurring syncs with small deltas, a shorter timeout helps detect stuck pipelines early.</p> <p>Dispose the Engine</p> <p><code>SyncEngine</code> implements <code>IAsyncDisposable</code>. Use <code>await using</code> to ensure all resources (adapters, file handles, connections) are cleaned up after the pipeline completes.</p>"},{"location":"integrations/sync-agent/logging.html","title":"Logging &amp; Monitoring","text":"<p>The ADP Sync Agent provides a pluggable logging system that enables real-time progress tracking, structured logging, and integration with UI-based progress indicators. Multiple loggers can be registered simultaneously \u2014 for example, one for console/file logging and another for a real-time dashboard.</p>"},{"location":"integrations/sync-agent/logging.html#isyncenginelogger","title":"ISyncEngineLogger","text":"<p>The core logging interface. Implement this to create custom loggers that integrate with your monitoring infrastructure.</p> <pre><code>public interface ISyncEngineLogger\n{\n    IEnumerable&lt;SyncEngineLoggerStatus&gt; SyncTaskStatuses { get; }\n    SyncEngineLoggerStatus? CurrentSyncTaskStatus { get; }\n    string ID { get; }\n    string? SyncID { get; }\n    long? OperationTimeoutInSeconds { get; }\n    DateTime OperationStart { get; }\n\n    ISyncEngineLogger SetOperationTimeoutInSeconds(long? seconds);\n    ISyncEngineLogger SetOperationStart(DateTime startDate);\n    ValueTask&lt;ISyncEngineLogger&gt; SetSyncTaskStatus(SyncEngineLoggerStatus syncTaskStatus);\n    ValueTask LogInformation(string? message, params object?[] args);\n    ValueTask LogError(string? message, params object?[] args);\n    ValueTask LogError(Exception? exception, string? message, params object?[] args);\n    ValueTask LogWarning(string? message, params object?[] args);\n    ValueTask FailAllRunningTasks();\n    ValueTask CompleteAllRunningTasks();\n}\n</code></pre>"},{"location":"integrations/sync-agent/logging.html#registering-loggers","title":"Registering Loggers","text":"<p>Register one or more loggers on the Sync Engine before calling <code>RunAsync</code>:</p> <pre><code>var engine = new SyncEngine&lt;SourceModel, DestModel&gt;();\n\nengine\n    .Configure(batchSize: 500)\n    .RegisterLogger(new SyncEngineILogger(logger))\n    .RegisterLogger(new SyncProgressIndicatorLogger(dashboardIndicator));\n\nawait engine.RunAsync();\n</code></pre>"},{"location":"integrations/sync-agent/logging.html#built-in-logger-implementations","title":"Built-in Logger Implementations","text":""},{"location":"integrations/sync-agent/logging.html#syncengineilogger","title":"SyncEngineILogger","text":"<p>Bridges the Sync Agent logging system with the standard <code>Microsoft.Extensions.Logging.ILogger</code> interface. Use this when you want pipeline events to flow through your existing logging infrastructure (Serilog, Application Insights, console, etc.).</p> <pre><code>var logger = loggerFactory.CreateLogger(\"SyncAgent\");\nengine.RegisterLogger(new SyncEngineILogger(logger));\n</code></pre> <p>Log messages from adapters and lifecycle stages are forwarded as <code>LogInformation</code>, <code>LogWarning</code>, or <code>LogError</code> calls to the underlying <code>ILogger</code>.</p>"},{"location":"integrations/sync-agent/logging.html#syncprogressindicatorlogger","title":"SyncProgressIndicatorLogger","text":"<p>Bridges the Sync Agent logging system with the <code>ISyncProgressIndicator</code> interface \u2014 designed for UI-based progress visualization. This logger maps the internal <code>SyncEngineLoggerStatus</code> to <code>SyncTaskStatus</code> objects that can be consumed by dashboards or progress bars.</p> <pre><code>engine.RegisterLogger(new SyncProgressIndicatorLogger(myDashboardIndicator));\n</code></pre>"},{"location":"integrations/sync-agent/logging.html#progress-tracking","title":"Progress Tracking","text":"<p>The Sync Engine automatically updates all registered loggers at each lifecycle stage. The <code>SyncEngineLoggerStatus</code> object provides rich progress information:</p> Property Type Description <code>OperationType</code> <code>SyncOperationType</code> Current lifecycle stage (Preparing, BatchStarted, Mapping, etc.). <code>ActionType</code> <code>SyncActionType?</code> Current action type (Add, Update, Delete). <code>CurrentStep</code> <code>long</code> Current batch index (1-based after increment). <code>TotalStep</code> <code>long?</code> Total number of batches (if known). <code>BatchSize</code> <code>long?</code> Configured batch size. <code>TotalCount</code> <code>long?</code> Total item count (if known). <code>CurrentRetryCount</code> <code>long?</code> Current retry attempt for this batch. <code>MaxRetryCount</code> <code>long?</code> Maximum retries allowed. <code>Progress</code> <code>double</code> Completion percentage (0.0 to 1.0). <code>Elapsed</code> <code>TimeSpan</code> Time elapsed since pipeline start. <code>RemainingTimeToShutdown</code> <code>TimeSpan</code> Time remaining before the operation timeout."},{"location":"integrations/sync-agent/logging.html#progress-example","title":"Progress Example","text":"<p>With a batch size of 100 and 1,000 total items, the logger will receive 10 progress updates for each action type \u2014 enabling a progress bar like:</p> <pre><code>[\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591] 40% \u2014 Batch 4/10 \u2014 Add \u2014 Elapsed: 00:01:23 \u2014 Remaining: 00:03:37\n</code></pre>"},{"location":"integrations/sync-agent/logging.html#logging-from-adapters","title":"Logging from Adapters","text":"<p>Within any lifecycle stage, adapters can log messages through the <code>SyncProgressIndicators</code> collection available on every <code>SyncFunctionInput</code>:</p> <pre><code>engine.SetupPreparing(async input =&gt;\n{\n    await input.SyncProgressIndicators.LogInformation(\"Loading CSV file for comparison...\");\n\n    // ... do work ...\n\n    await input.SyncProgressIndicators.LogInformation(\"Found 342 added lines and 17 deleted lines.\");\n\n    return SyncPreparingResponseAction.Succeeded;\n});\n</code></pre> <p>The <code>IEnumerableExtensions</code> provide convenient extension methods for broadcasting log messages to all registered loggers at once:</p> <ul> <li><code>LogInformation(message, args)</code></li> <li><code>LogWarning(message, args)</code></li> <li><code>LogError(message, args)</code></li> <li><code>LogError(exception, message, args)</code></li> </ul>"},{"location":"integrations/sync-agent/logging.html#isyncprogressindicator","title":"ISyncProgressIndicator","text":"<p>The <code>ISyncProgressIndicator</code> interface is a simplified UI-oriented contract for displaying sync progress to end users:</p> <pre><code>public interface ISyncProgressIndicator\n{\n    Task LogInformationAsync(SyncTaskStatus syncTask, string message);\n    Task LogErrorAsync(SyncTaskStatus syncTask, string message);\n    Task LogWarningAsync(SyncTaskStatus syncTask, string message);\n    Task FailAllRunningTasks();\n    Task CompleteAllRunningTasks();\n}\n</code></pre> <p>Implement this interface to feed progress data into your application's UI \u2014 whether it's a Blazor dashboard, a SignalR-powered web page, or a WPF application.</p> <p>The <code>SyncProgressIndicatorLogger</code> class bridges the engine's <code>ISyncEngineLogger</code> interface to your <code>ISyncProgressIndicator</code> implementation.</p>"},{"location":"integrations/sync-agent/logging.html#legacy-ilogger-extension","title":"Legacy ILogger Extension","text":"<p>For simpler scenarios, the <code>AddLogger</code> extension method wraps an existing <code>ILogger</code> to provide automatic lifecycle logging without implementing <code>ISyncEngineLogger</code>:</p> <pre><code>engine.AddLogger(logger);\n</code></pre> <p>Deprecated</p> <p>The <code>AddLogger(ILogger)</code> extension is marked as <code>[Obsolete]</code>. Use <code>RegisterLogger</code> with an <code>ISyncEngineLogger</code> implementation for better async support and extensibility.</p> <p>This extension automatically logs:</p> <ul> <li>Preparing start/result</li> <li>Action start</li> <li>Source total item count</li> <li>Batch start with step and total</li> <li>Source batch item retrieval</li> <li>Mapping</li> <li>Storage results (succeeded/failed/skipped counts)</li> <li>Batch completion</li> <li>Action completion</li> <li>Overall success/failure</li> </ul>"},{"location":"integrations/sync-agent/resilience.html","title":"Resilience &amp; Fault Tolerance","text":"<p>Reliable data synchronization requires careful handling of failures. Networks go down, databases become temporarily unavailable, and API rate limits are hit. The ADP Sync Agent is designed to handle these scenarios gracefully, ensuring that transient failures don't result in data loss or inconsistent states.</p>"},{"location":"integrations/sync-agent/resilience.html#retry-strategies","title":"Retry Strategies","text":"<p>When a batch fails \u2014 whether due to a storage exception, a timeout, or a <code>RetryException</code> returned by <code>StoreBatchData</code> \u2014 the Sync Engine enters the retry flow.</p> <pre><code>flowchart TD\n    F[Batch Failed] --&gt; BR{BatchRetry Handler?}\n    BR --&gt;|Yes| RA[Return RetryAction]\n    BR --&gt;|No| DA[Use Default RetryAction]\n\n    RA --&gt; D{Decision}\n    DA --&gt; D\n\n    D --&gt;|Retry*| R[Increment Retry Count]\n    R --&gt; MC{retryCount &gt; maxRetryCount?}\n    MC --&gt;|No| RE[Re-execute Batch]\n\n    MC --&gt;|Yes, RetryAndStop| STOP[Stop Action]\n    MC --&gt;|Yes, RetryAndContinue| BC[BatchCompleted \u2192 Next Batch]\n\n    D --&gt;|Skip| BC\n    D --&gt;|Stop| STOP</code></pre>"},{"location":"integrations/sync-agent/resilience.html#retryaction-options","title":"RetryAction Options","text":"Strategy Behavior <code>RetryAndStopAfterLastRetry</code> Retry the batch up to <code>MaxRetryCount</code> times. If all retries are exhausted, stop the entire action and mark it as failed. <code>BatchCompleted</code> is not invoked. This is the default strategy. <code>RetryAndContinueAfterLastRetry</code> Retry the batch up to <code>MaxRetryCount</code> times. If all retries are exhausted, invoke <code>BatchCompleted</code> and move to the next batch. Use this when partial success is acceptable. <code>Skip</code> Skip the failed batch immediately without retrying and move to the next batch. <code>BatchCompleted</code> is invoked. <code>Stop</code> Stop the entire action immediately without retrying. <code>BatchCompleted</code> is not invoked."},{"location":"integrations/sync-agent/resilience.html#configuring-retries","title":"Configuring Retries","text":"<p>Set the default retry behavior at the engine level:</p> <pre><code>engine.Configure(\n    batchSize: 500,\n    maxRetryCount: 3,\n    defaultRetryAction: RetryAction.RetryAndContinueAfterLastRetry);\n</code></pre> <p>Override the default on a per-batch basis using the <code>BatchRetry</code> handler:</p> <pre><code>engine.SetupBatchRetry(async input =&gt;\n{\n    // Log the error\n    Console.WriteLine($\"Batch {input.Input.Status.CurrentStep} failed: {input.Input.Exception?.Message}\");\n\n    // Custom logic: stop immediately for critical errors\n    if (input.Input.Exception is UnauthorizedAccessException)\n        return RetryAction.Stop;\n\n    // Otherwise, retry\n    return RetryAction.RetryAndStopAfterLastRetry;\n});\n</code></pre>"},{"location":"integrations/sync-agent/resilience.html#retry-behavior-in-adapters","title":"Retry Behavior in Adapters","text":"<p>The retry system is integrated into the built-in adapters at multiple levels:</p>"},{"location":"integrations/sync-agent/resilience.html#source-data-on-retry","title":"Source Data on Retry","text":"<p>When a batch is retried, the <code>GetSourceBatchItems</code> stage receives the previous batch items via <code>SyncGetBatchDataInput.PreviousItems</code>. Built-in source adapters automatically return the previous items on retry, avoiding redundant reads from the source.</p>"},{"location":"integrations/sync-agent/resilience.html#mapping-on-retry","title":"Mapping on Retry","text":"<p>The simple mapping (<code>SetupMapping</code>) automatically reuses previously mapped items on retry \u2014 avoiding unnecessary re-transformation. The advanced mapping (<code>SetupAdvancedMapping</code>) gives you full control via <code>SyncMappingInput.PreviousMappedItem</code>.</p>"},{"location":"integrations/sync-agent/resilience.html#storage-on-retry","title":"Storage on Retry","text":"<p>The <code>StoreBatchData</code> stage receives the previous result via <code>SyncStoreDataInput.PreviousResult</code>. Adapters like <code>CosmosSyncDataDestination</code> use this to retry only the failed items from the previous attempt, rather than re-processing the entire batch.</p>"},{"location":"integrations/sync-agent/resilience.html#cosmos-db-retry-pipeline","title":"Cosmos DB Retry Pipeline","text":"<p>The Cosmos DB destination adapter includes an additional layer of resilience powered by Polly. Each individual Cosmos DB operation (upsert or delete) is wrapped in a Polly retry pipeline that handles transient HTTP failures and rate limiting (HTTP 429).</p> <p>This means a single batch may succeed even if individual items experience transient failures \u2014 they are retried transparently before the batch result is computed.</p>"},{"location":"integrations/sync-agent/resilience.html#atomic-execution","title":"Atomic Execution","text":"<p>A pipeline execution is considered successful only if all critical operations complete:</p> <ol> <li>Reading from the source.</li> <li>Transforming the data.</li> <li>Writing to the destination.</li> <li>Marking the source as synced (e.g., updating timestamps, storing the synced CSV file).</li> </ol> <p>If any of these steps fail, the pipeline reports failure. The developer controls whether partial results are committed based on the retry strategy and the <code>BatchCompleted</code> handler.</p>"},{"location":"integrations/sync-agent/resilience.html#csv-source-atomicity","title":"CSV Source Atomicity","text":"<p>The CSV source adapter implements atomicity through a two-phase approach:</p> <ul> <li>During processing, changes are written to the destination.</li> <li>Only on <code>Succeeded</code>, the new version of the CSV file is stored to the content repository.</li> <li>If the pipeline fails, the next run will re-compare against the same baseline, automatically picking up the un-synced changes.</li> </ul>"},{"location":"integrations/sync-agent/resilience.html#ef-core-source-atomicity","title":"EF Core Source Atomicity","text":"<p>The EF Core source adapter updates the <code>SyncTimestamp</code> property on source records in the <code>BatchCompleted</code> stage. If the pipeline fails before this point, those records remain eligible for sync on the next run.</p>"},{"location":"integrations/sync-agent/resilience.html#operation-timeouts","title":"Operation Timeouts","text":"<p>Every pipeline execution has a timeout configured via <code>operationTimeoutInSeconds</code> (default: 300 seconds). A <code>CancellationToken</code> is created with this timeout and passed to every stage.</p> <p>When the timeout expires:</p> <ol> <li>The cancellation token is triggered.</li> <li>An <code>OperationCanceledException</code> is raised at the next cancellation check.</li> <li>The <code>Failed</code> handler is invoked.</li> <li>The <code>Finished</code> handler is invoked for cleanup.</li> </ol> <p>Timeout Planning</p> <p>Set the timeout generously enough to accommodate the total data volume, batch size, and expected latency of your source and destination systems. For large initial syncs, consider using a longer timeout or breaking the work into smaller pipeline runs.</p>"},{"location":"integrations/sync-agent/resilience.html#error-handling-lifecycle","title":"Error Handling Lifecycle","text":"<p>The Sync Engine provides three stages for handling pipeline-level errors:</p> Stage When Called Purpose <code>Failed</code> When the pipeline fails (any action fails or an unhandled exception is thrown). Logging, alerting, cleanup of partial state. Receives the exception if available. <code>Succeeded</code> When all actions complete successfully. Post-success operations like storing the synced CSV file or sending notifications. <code>Finished</code> Always called at the end, regardless of outcome. Final cleanup \u2014 deleting temp files, disposing resources. <pre><code>engine\n    .SetupFailed(async input =&gt;\n    {\n        logger.LogError(input.Input, \"Pipeline failed\");\n        await alertService.SendAlertAsync(\"Sync pipeline failed\");\n    })\n    .SetupSucceeded(async input =&gt;\n    {\n        logger.LogInformation(\"Pipeline completed successfully\");\n    })\n    .SetupFinished(async input =&gt;\n    {\n        // Always runs \u2014 clean up resources\n        await tempFileService.CleanupAsync();\n    });\n</code></pre>"},{"location":"web-components/installation.html","title":"Installation","text":"<p>ADP Web Components offers two installation methods: Bundle Installation and Standalone Installation, depending on your project requirements. Both methods support Latest Version CDN links and Versioned CDN links for flexibility.</p>"},{"location":"web-components/installation.html#versioned-vs-latest-cdn-links","title":"Versioned vs. Latest CDN Links","text":"<p>ADP Web Components supports two CDN types:</p> <ul> <li> <p>Versioned CDN (Recommended):   Use a specific version of the ADP components library by specifying the version number after the <code>@</code> symbol in the CDN link (e.g., <code>@0.0.20</code>). This ensures stability as updates won\u2019t affect your implementation.</p> </li> <li> <p>Latest CDN:   Automatically uses the most recent updates when components are released. Specify <code>@latest</code> in the CDN link.</p> </li> </ul>"},{"location":"web-components/installation.html#pros-and-cons","title":"Pros and Cons","text":"<p>Cons</p> <ul> <li>Versioned CDN: If bugs in your version are fixed in newer releases, you must manually update your version and code.</li> <li>Latest CDN: Updates to components (e.g., changes in methods or callbacks) might break your code, requiring adjustments.</li> </ul> <p>Pros</p> <ul> <li>Versioned CDN: Ensures stability by locking in the version, avoiding breaking changes in newer releases.</li> <li>Latest CDN: Automatically applies bug fixes and new features as they are released.</li> </ul>"},{"location":"web-components/installation.html#example-cdn-links","title":"Example CDN Links","text":"Versioned CDN (Recommended)Latest CDN <p>Bundle (e.g., 0.0.20):</p> <pre><code>&lt;script type=\"module\" src=\"https://cdn.jsdelivr.net/npm/adp-web-components@0.0.20/dist/shift-components/shift-components.esm.js\"&gt;&lt;/script&gt;\n</code></pre> <p>Standalone (e.g., 0.0.20):</p> <pre><code>&lt;script type=\"module\" src=\"https://cdn.jsdelivr.net/npm/adp-web-components@0.0.20/dist/components/dynamic-claim.js\"&gt;&lt;/script&gt;\n</code></pre> <p>Bundle (Latest):</p> <pre><code>&lt;script type=\"module\" src=\"https://cdn.jsdelivr.net/npm/adp-web-components@latest/dist/shift-components/shift-components.esm.js\"&gt;&lt;/script&gt;\n</code></pre> <p>Standalone (Latest):</p> <pre><code>&lt;script type=\"module\" src=\"https://cdn.jsdelivr.net/npm/adp-web-components@latest/dist/components/dynamic-claim.js\"&gt;&lt;/script&gt;\n</code></pre>"},{"location":"web-components/installation.html#bundled-vs-standalone","title":"Bundled vs. Standalone","text":"<p>Installation ADP Web Components offers two installation methods:</p> <ul> <li>Bundled CDN: Includes all components in one CDN. Useful for projects requiring multiple components. All components listed in Component List for more details.</li> <li>Standalone CDN (Recommended): Loads individual components, offering a lightweight and efficient solution for targeted use cases.</li> </ul>"},{"location":"web-components/installation.html#pros-and-cons_1","title":"Pros and Cons","text":"<p>Cons</p> <ul> <li>Bundled CDN: Larger file size compared to standalone components. Bundle are not lazy-loaded in most of the times but still its highly recommended to use <code>document.addEventListener('DOMContentLoaded', () =&gt; {})</code>.</li> <li>Standalone CDN: Requires <code>document.addEventListener('DOMContentLoaded', () =&gt; {})</code> due to lazy-loaded components.</li> </ul> <p>Pros</p> <ul> <li>Bundled CDN: Convenient for projects using multiple components, as all components are imported together.</li> <li>Standalone CDN: Lightweight, as only the required component is imported.</li> </ul>"},{"location":"web-components/installation.html#example-installation-links","title":"Example Installation Links","text":"Bundled CDNStandalone CDN <p>Latest: <pre><code>&lt;script type=\"module\" src=\"https://cdn.jsdelivr.net/npm/adp-web-components@latest/dist/shift-components/shift-components.esm.js\"&gt;&lt;/script&gt;\n</code></pre> Versioned (e.g., 0.0.20): <pre><code>&lt;script type=\"module\" src=\"https://cdn.jsdelivr.net/npm/adp-web-components@0.0.20/dist/shift-components/shift-components.esm.js\"&gt;&lt;/script&gt;\n</code></pre></p> <p>Latest: <pre><code>&lt;script type=\"module\" src=\"https://cdn.jsdelivr.net/npm/adp-web-components@latest/dist/components/dynamic-claim.js\"&gt;&lt;/script&gt;\n</code></pre></p> <p>Versioned (e.g., 0.0.20): <pre><code>&lt;script type=\"module\" src=\"https://cdn.jsdelivr.net/npm/adp-web-components@0.0.20/dist/components/dynamic-claim.js\"&gt;&lt;/script&gt;\n</code></pre></p>"},{"location":"web-components/installation.html#usage","title":"Usage","text":"<p>The usage of components remains consistent regardless of CDN type (Versioned vs. Latest) or installation method (Bundled vs. Standalone). However, using<code>document.addEventListener('DOMContentLoaded', () =&gt; {})</code> is highly recommended for reliable initialization.</p> Bundle UsageStandalone Usage <p>HTML code with DOMContentLoaded Recommended</p> <pre><code>&lt;script type=\"module\" src=\"https://cdn.jsdelivr.net/npm/adp-web-components@latest/dist/shift-components/shift-components.esm.js\"&gt;&lt;/script&gt;\n\n&lt;dynamic-redeem id=\"dynamic-redeem\"&gt;&lt;/dynamic-redeem&gt;\n&lt;dynamic-claim is-dev=\"true\" base-url=\"http://localhost:7174/api/secure-vehicle-lookup-test/\" id=\"dynamic-claim\"&gt;&lt;/dynamic-claim&gt;\n\n&lt;script&gt;\n  let dynamicClaim\n  let dynamicRedeem\n\n  document.addEventListener('DOMContentLoaded', () =&gt; {\n    dynamicClaim = document.getElementById('dynamic-claim');\n    dynamicRedeem = document.getElementById('dynamic-redeem');\n    // Add your JavaScript logic here\n  });\n&lt;/script&gt;\n</code></pre> <p>HTML code without DOMContentLoaded</p> <pre><code>&lt;script type=\"module\" src=\"https://cdn.jsdelivr.net/npm/adp-web-components@latest/dist/shift-components/shift-components.esm.js\"&gt;&lt;/script&gt;\n\n&lt;dynamic-redeem id=\"dynamic-redeem\"&gt;&lt;/dynamic-redeem&gt;\n&lt;dynamic-claim is-dev=\"true\" base-url=\"http://localhost:7174/api/secure-vehicle-lookup-test/\" id=\"dynamic-claim\"&gt;&lt;/dynamic-claim&gt;\n\n&lt;script&gt;\n    const dynamicClaim = document.getElementById('dynamic-claim');\n    const dynamicRedeem = document.getElementById('dynamic-redeem');\n&lt;/script&gt;\n</code></pre> <p>Becarefull in Standing mode you have to import each component separately and its mandatory to use <code>DOMContentLoaded</code></p> <pre><code>&lt;script type=\"module\" src=\"https://cdn.jsdelivr.net/npm/adp-web-components@latest/dist/components/dynamic-claim.js\"&gt;&lt;/script&gt;\n\n&lt;script type=\"module\" src=\"https://cdn.jsdelivr.net/npm/adp-web-components@latest/dist/components/dynamic-redeem.js\"&gt;&lt;/script&gt;\n\n&lt;dynamic-redeem id=\"dynamic-redeem\"&gt;&lt;/dynamic-redeem&gt;\n&lt;dynamic-claim is-dev=\"true\" base-url=\"http://localhost:7174/api/secure-vehicle-lookup-test/\" id=\"dynamic-claim\"&gt;&lt;/dynamic-claim&gt;\n\n&lt;script&gt;\n  let dynamicClaim\n  let dynamicRedeem\n\n  document.addEventListener('DOMContentLoaded', () =&gt; {\n    dynamicClaim = document.getElementById('dynamic-claim');\n    dynamicRedeem = document.getElementById('dynamic-redeem');\n    // Add your JavaScript logic here\n  });\n&lt;/script&gt;\n</code></pre>"},{"location":"web-components/installation.html#next-steps","title":"Next Steps","text":"<ul> <li>Explore the Theming Guide for customization.</li> <li>Refer to the Component List for detailed documentation.</li> </ul>"},{"location":"web-components/introduction.html","title":"Introduction","text":""},{"location":"web-components/introduction.html#welcome-to-adp-web-components","title":"Welcome to ADP Web Components","text":"<p>The ADP Web Components project, provides developers with a collection of reusable web components tailored to enhance the functionality and make it easier to use and adapt the components on any frontend framework or library from developer choice.</p> <p>These components are designed with a focus on:</p> <ul> <li>Efficiency: Optimized for seamless functionality.</li> <li>Lightweight design: Ensuring minimal performance impact.</li> <li>Compatibility: Usable across various frameworks and environments.</li> </ul>"},{"location":"web-components/introduction.html#why-use-adp-web-components","title":"Why Use ADP Web Components?","text":"<ul> <li>Standalone Flexibility: Components can be used individually with lazy loading for better performance.</li> <li>Bundle Support: Alternatively, leverage the entire library for streamlined integration.</li> <li>Framework-Agnostic: Easily integrate into any web project, regardless of the framework.</li> </ul> <p>This documentation will guide you through installation methods, examples, and a complete list of components available.</p>"},{"location":"web-components/introduction.html#features-at-a-glance","title":"Features at a Glance","text":"<ul> <li>Bundle Installation: Access all components with a single script.</li> <li>Standalone Installation: Includes lazy-loaded components for targeted use.</li> <li>Comprehensive Documentation: Detailed guides for each component's usage.</li> </ul> <p>Navigate through the documentation to explore the features and start building with ADP Web Components today.</p> <p> </p> <ul> <li>Installation Guide.</li> </ul>"},{"location":"web-components/theming.html","title":"Theming","text":"<p>ADP Component styles can be customized by targeting each element inside the component which gives flexibility to developers to apply their custom themes from any project.</p>"},{"location":"web-components/theming.html#adp-components","title":"ADP Components","text":"<p>ADP Components are web components created from StencilJS project and enables shadow dom feature making the component not effected by most of outside styles.</p>"},{"location":"web-components/theming.html#what-is-web-components","title":"What is Web Components?","text":"<p>Web Components are a set of native browser technologies that allow developers to create reusable, encapsulated, and modular custom elements for web applications. They provide a standardized way to build and use UI components across different frameworks, libraries, or even vanilla JavaScript, ensuring better reusability and maintainability.</p>"},{"location":"web-components/theming.html#what-is-shadow-dom","title":"What is Shadow DOM?","text":"<p>The Shadow DOM is a web standard that allows developers to encapsulate a component's structure, style, and behavior, preventing it from being affected by styles or scripts outside the component and vice versa. It is part of the Web Components specification.</p>"},{"location":"web-components/theming.html#how-to-style","title":"How to style","text":"<p>Developers can target each element inside the components using <code>part::</code> selector in CSS.</p> <p>lets consider our imaginary <code>custom-element</code> has the following structure.</p> <pre><code>&lt;div part=\"custom-element\"&gt;\n  &lt;div part=\"custom-element-header\"&gt;&lt;/div&gt;\n\n  &lt;div part=\"custom-element-body\"&gt;\n    &lt;p part=\"custom-element-number\"&gt;&lt;/p&gt;\n  &lt;/div&gt;\n\n  &lt;div part=\"custom-element-footer\"&gt;&lt;/div&gt;\n&lt;/div&gt;\n</code></pre> <p>Custom styling example.</p> <pre><code>&lt;style&gt;\n  part(custom-element-header) {\n    color: yellow !important;\n  }\n\n  #red::part(custom-element-header) {\n    color: red !important;\n  }\n\n  .green::part(custom-element-header) {\n    color: green !important;\n  }\n&lt;/style&gt;\n\n&lt;body&gt;\n  &lt;custom-element&gt;&lt;/custom-element&gt;\n  &lt;custom-element id=\"red\"&gt;&lt;/custom-element&gt;\n  &lt;custom-element class=\"green\"&gt;&lt;/custom-element&gt;\n  &lt;custom-element class=\"green\"&gt;&lt;/custom-element&gt;\n&lt;/body&gt;\n</code></pre>"},{"location":"web-components/theming.html#how-to-find-part-names","title":"How to find part names","text":"<p>Developers can find parts in 2 ways</p> <ul> <li>Each Component in their dedicated documentation has Structure section where their structure is showed similar to the above structure.</li> <li>Developers can explore the components and find out what is each element part names using browser devtools, as showed in the bellow image.</li> </ul> <p></p>"},{"location":"web-components/theming.html#next-steps","title":"Next Steps","text":"<ul> <li>Read to the Component List for detailed documentation.</li> </ul>"},{"location":"web-components/components/components-list.html","title":"Components List","text":"<p>This section provided all the components Full Documentation, Demo, Component Structure, some basic manipulation on some of the components.</p> <p>Important</p> <p>Some components as example of Vehicle Lookup are only wrappers around other components and doesn't have a shadow dom of their own.</p> Vehicle Lookup <ul> <li>Vehicle Lookup Wrapper</li> <li>Vehicle Specification</li> <li>Vehicle Accessories</li> <li>Warranty Details</li> <li>Service History</li> <li>Paint Thickness</li> <li>Swift Claim</li> </ul> Vehicle Parts <ul> <li>Dead Stock Lookup</li> <li>Distributor Lookup</li> <li>Manufacturer Lookup</li> </ul>"},{"location":"web-components/components/dead-stock-lookup.html","title":"Dead Stock Lookup","text":"<p>\ud83d\udea7 Documentation In Progress</p> <p>\ud83d\udcda Full documentation will be added soon. Please stay tuned for updates! \ud83d\udd14</p>"},{"location":"web-components/components/distributor-lookup.html","title":"Distributor Lookup","text":"<p>\ud83d\udea7 Documentation In Progress</p> <p>\ud83d\udcda Full documentation will be added soon. Please stay tuned for updates! \ud83d\udd14</p>"},{"location":"web-components/components/manufacturer-lookup.html","title":"Manufacturer Lookup","text":"<p>\ud83d\udea7 Documentation In Progress</p> <p>\ud83d\udcda Full documentation will be added soon. Please stay tuned for updates! \ud83d\udd14</p>"},{"location":"web-components/components/paint-thickness.html","title":"Paint Thickness","text":"<p>\ud83d\udea7 Documentation In Progress</p> <p>\ud83d\udcda Full documentation will be added soon. Please stay tuned for updates! \ud83d\udd14</p>"},{"location":"web-components/components/service-history.html","title":"Service History","text":"<p>\ud83d\udea7 Documentation In Progress</p> <p>\ud83d\udcda Full documentation will be added soon. Please stay tuned for updates! \ud83d\udd14</p>"},{"location":"web-components/components/swift-claim.html","title":"Swift Claim","text":"<p>\ud83d\udea7 Documentation In Progress</p> <p>\ud83d\udcda Full documentation will be added soon. Please stay tuned for updates! \ud83d\udd14</p>"},{"location":"web-components/components/vehicle-accessories.html","title":"Vehicle Accessories","text":"<p>\ud83d\udea7 Documentation In Progress</p> <p>\ud83d\udcda Full documentation will be added soon. Please stay tuned for updates! \ud83d\udd14</p>"},{"location":"web-components/components/vehicle-lookup.html","title":"Vehicle Lookup","text":"<p>\ud83d\udea7 Documentation In Progress</p> <p>\ud83d\udcda Full documentation will be added soon. Please stay tuned for updates! \ud83d\udd14</p>"},{"location":"web-components/components/vehicle-specification.html","title":"Vehicle Specification","text":"<p>\ud83d\udea7 Documentation In Progress</p> <p>\ud83d\udcda Full documentation will be added soon. Please stay tuned for updates! \ud83d\udd14</p>"},{"location":"web-components/components/warranty-details.html","title":"Warranty Details","text":"<p>\ud83d\udea7 Documentation In Progress</p> <p>\ud83d\udcda Full documentation will be added soon. Please stay tuned for updates! \ud83d\udd14</p>"}]}